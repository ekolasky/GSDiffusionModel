{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize labeled dataset from CO3D\n",
    "You can ignore this section if labeled dataset is already in S3 bucket (in which case skip to the next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories to process: hydrant\n",
      "Processing category: hydrant\n",
      "data/labeled_gs/raw/hydrant/hydrant_004.zip: 100%|█| 18.8G/18.8G [1:11:38<00:00,\n",
      "Extracting: 100%|████████████████████████| 55524/55524 [06:18<00:00, 146.62it/s]\n",
      "Finished processing category: hydrant\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "\n",
    "!cd .. && python -m scripts.dataset.labeled.download_labeled_dataset --category hydrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure verified. Found 1 category folders.\n",
      "Processing category: hydrant\n",
      "Processing folder: data/labeled_gs/raw/hydrant/hydrant\n",
      "Could not find 605_94563_187702\n",
      "Point cloud doesn't exist in 167_18178_34131\n",
      "Point cloud doesn't exist in 431_60829_118045\n",
      "Point cloud doesn't exist in 431_60878_118375\n",
      "Point cloud doesn't exist in 431_60946_118759\n",
      "Point cloud doesn't exist in 431_60947_118760\n",
      "Point cloud doesn't exist in 433_61357_119791\n",
      "Point cloud doesn't exist in 433_61366_119705\n",
      "Point cloud doesn't exist in 433_61519_120299\n",
      "Could not find 435_61818_120849\n",
      "Could not find 435_61835_120916\n",
      "Could not find 435_61855_121105\n",
      "Could not find 435_61866_121155\n",
      "Could not find 437_62456_122691\n",
      "Could not find 437_62534_123476\n",
      "Could not find 437_62537_123492\n",
      "Could not find 439_62866_124111\n",
      "Could not find 439_62967_124664\n",
      "Could not find 462_65401_128449\n",
      "Could not find 469_66166_130137\n",
      "Could not find 471_66628_131251\n",
      "Could not find 473_66962_131717\n",
      "Could not find 478_67940_132968\n",
      "Could not find 481_68761_134003\n",
      "Could not find 481_68795_134273\n",
      "Could not find 481_68808_134362\n",
      "Could not find 481_68829_134717\n",
      "Could not find 491_70272_136794\n",
      "Could not find 494_70826_138427\n",
      "Could not find 505_72738_142070\n",
      "Could not find 536_77998_151472\n",
      "Could not find 554_79515_154532\n",
      "Could not find 554_79592_157155\n",
      "Could not find 557_80260_157542\n",
      "Could not find 572_83686_165398\n",
      "Could not find 576_84893_167533\n",
      "Could not find 576_84894_167447\n",
      "Could not find 580_86067_169496\n",
      "Could not find 582_86640_171043\n",
      "Could not find 587_87877_173282\n",
      "Could not find 590_88793_174590\n",
      "Could not find 596_91114_180726\n",
      "Could not find 599_92237_181404\n",
      "Could not find 599_92248_182245\n",
      "Could not find 599_92301_183375\n",
      "Could not find 599_92368_184475\n",
      "Could not find 605_94530_187400\n",
      "Could not find 607_95527_190940\n",
      "Could not find 615_99023_197350\n",
      "Could not find 621_101747_202350\n",
      "Could not find 625_103554_206496\n",
      "Added COLMAP data to 106_12648_23157\n",
      "Removed background from images in 106_12648_23157\n",
      "Added COLMAP data to 106_12653_23216\n",
      "Removed background from images in 106_12653_23216\n",
      "Added COLMAP data to 106_12660_22718\n",
      "Removed background from images in 106_12660_22718\n",
      "Added COLMAP data to 106_12669_24034\n",
      "Removed background from images in 106_12669_24034\n",
      "Added COLMAP data to 106_12677_24990\n",
      "Removed background from images in 106_12677_24990\n",
      "Added COLMAP data to 106_12686_26118\n",
      "Removed background from images in 106_12686_26118\n",
      "Added COLMAP data to 106_12687_26288\n",
      "Removed background from images in 106_12687_26288\n",
      "Added COLMAP data to 106_12698_26785\n",
      "Removed background from images in 106_12698_26785\n",
      "Added COLMAP data to 116_13648_27584\n",
      "Removed background from images in 116_13648_27584\n",
      "Added COLMAP data to 116_13651_28370\n",
      "Removed background from images in 116_13651_28370\n",
      "Added COLMAP data to 116_13653_28885\n",
      "Removed background from images in 116_13653_28885\n",
      "Added COLMAP data to 116_13660_28980\n",
      "Removed background from images in 116_13660_28980\n",
      "Added COLMAP data to 134_15449_31106\n",
      "Removed background from images in 134_15449_31106\n",
      "Added COLMAP data to 134_15450_30933\n",
      "Removed background from images in 134_15450_30933\n",
      "Added COLMAP data to 134_15451_31119\n",
      "Removed background from images in 134_15451_31119\n",
      "Added COLMAP data to 134_15455_31174\n",
      "Removed background from images in 134_15455_31174\n",
      "Added COLMAP data to 134_15456_31334\n",
      "Removed background from images in 134_15456_31334\n",
      "Added COLMAP data to 147_16374_32167\n",
      "Removed background from images in 147_16374_32167\n",
      "Added COLMAP data to 157_17275_32769\n",
      "Removed background from images in 157_17275_32769\n",
      "Added COLMAP data to 157_17285_33524\n",
      "Removed background from images in 157_17285_33524\n",
      "Added COLMAP data to 157_17287_33549\n",
      "Removed background from images in 157_17287_33549\n",
      "Added COLMAP data to 157_17288_33665\n",
      "Removed background from images in 157_17288_33665\n",
      "Added COLMAP data to 167_18176_34398\n",
      "Removed background from images in 167_18176_34398\n",
      "Added COLMAP data to 167_18177_33907\n",
      "Removed background from images in 167_18177_33907\n",
      "Added COLMAP data to 167_18181_34401\n",
      "Removed background from images in 167_18181_34401\n",
      "Added COLMAP data to 167_18184_34441\n",
      "Removed background from images in 167_18184_34441\n",
      "Added COLMAP data to 167_18186_34890\n",
      "Removed background from images in 167_18186_34890\n",
      "Added COLMAP data to 167_18191_34823\n",
      "Removed background from images in 167_18191_34823\n",
      "Added COLMAP data to 167_18192_34876\n",
      "Removed background from images in 167_18192_34876\n",
      "Added COLMAP data to 185_19974_36741\n",
      "Removed background from images in 185_19974_36741\n",
      "Added COLMAP data to 185_19977_36602\n",
      "Removed background from images in 185_19977_36602\n",
      "Added COLMAP data to 185_19984_37720\n",
      "Removed background from images in 185_19984_37720\n",
      "Added COLMAP data to 185_19986_38630\n",
      "Removed background from images in 185_19986_38630\n",
      "Added COLMAP data to 185_19989_38870\n",
      "Removed background from images in 185_19989_38870\n",
      "Added COLMAP data to 185_19990_38942\n",
      "Removed background from images in 185_19990_38942\n",
      "Added COLMAP data to 185_19994_39389\n",
      "Removed background from images in 185_19994_39389\n",
      "Added COLMAP data to 185_19998_39437\n",
      "Removed background from images in 185_19998_39437\n",
      "Added COLMAP data to 194_20876_39736\n",
      "Removed background from images in 194_20876_39736\n",
      "Added COLMAP data to 194_20878_39742\n",
      "Removed background from images in 194_20878_39742\n",
      "Added COLMAP data to 194_20879_39973\n",
      "Removed background from images in 194_20879_39973\n",
      "Added COLMAP data to 194_20882_40735\n",
      "Removed background from images in 194_20882_40735\n",
      "Added COLMAP data to 194_20888_40801\n",
      "Removed background from images in 194_20888_40801\n",
      "Added COLMAP data to 194_20891_40947\n",
      "Removed background from images in 194_20891_40947\n",
      "Added COLMAP data to 194_20893_40953\n",
      "Removed background from images in 194_20893_40953\n",
      "Added COLMAP data to 194_20902_41099\n",
      "Removed background from images in 194_20902_41099\n",
      "Added COLMAP data to 194_20906_41104\n",
      "Removed background from images in 194_20906_41104\n",
      "Added COLMAP data to 194_20907_41105\n",
      "Removed background from images in 194_20907_41105\n",
      "Added COLMAP data to 194_20922_42215\n",
      "Removed background from images in 194_20922_42215\n",
      "Added COLMAP data to 194_20925_42241\n",
      "Removed background from images in 194_20925_42241\n",
      "Added COLMAP data to 194_20928_42530\n",
      "Removed background from images in 194_20928_42530\n",
      "Added COLMAP data to 194_20930_42343\n",
      "Removed background from images in 194_20930_42343\n",
      "Added COLMAP data to 194_20931_42673\n",
      "Removed background from images in 194_20931_42673\n",
      "Added COLMAP data to 194_20934_42349\n",
      "Removed background from images in 194_20934_42349\n",
      "Added COLMAP data to 194_20938_42675\n",
      "Removed background from images in 194_20938_42675\n",
      "Added COLMAP data to 194_20940_43635\n",
      "Removed background from images in 194_20940_43635\n",
      "Added COLMAP data to 194_20943_43312\n",
      "Removed background from images in 194_20943_43312\n",
      "Added COLMAP data to 194_20947_44496\n",
      "Removed background from images in 194_20947_44496\n",
      "Added COLMAP data to 194_20953_43984\n",
      "Removed background from images in 194_20953_43984\n",
      "Added COLMAP data to 194_20956_44543\n",
      "Removed background from images in 194_20956_44543\n",
      "Added COLMAP data to 194_20957_44512\n",
      "Removed background from images in 194_20957_44512\n",
      "Added COLMAP data to 206_21797_45640\n",
      "Removed background from images in 206_21797_45640\n",
      "Added COLMAP data to 206_21815_46194\n",
      "Removed background from images in 206_21815_46194\n",
      "Added COLMAP data to 206_21817_46200\n",
      "Removed background from images in 206_21817_46200\n",
      "Added COLMAP data to 206_21818_45959\n",
      "Removed background from images in 206_21818_45959\n",
      "Added COLMAP data to 206_21819_46352\n",
      "Removed background from images in 206_21819_46352\n",
      "Added COLMAP data to 216_22805_47495\n",
      "Removed background from images in 216_22805_47495\n",
      "Added COLMAP data to 216_22806_47497\n",
      "Removed background from images in 216_22806_47497\n",
      "Added COLMAP data to 216_22815_47624\n",
      "Removed background from images in 216_22815_47624\n",
      "Added COLMAP data to 216_22818_47639\n",
      "Removed background from images in 216_22818_47639\n",
      "Added COLMAP data to 216_22826_47834\n",
      "Removed background from images in 216_22826_47834\n",
      "Added COLMAP data to 216_22839_48459\n",
      "Removed background from images in 216_22839_48459\n",
      "Added COLMAP data to 216_22840_48460\n",
      "Removed background from images in 216_22840_48460\n",
      "Added COLMAP data to 216_22845_49619\n",
      "Removed background from images in 216_22845_49619\n",
      "Added COLMAP data to 216_22850_49616\n",
      "Removed background from images in 216_22850_49616\n",
      "Added COLMAP data to 216_22854_49630\n",
      "Removed background from images in 216_22854_49630\n",
      "Added COLMAP data to 216_22855_49631\n",
      "Removed background from images in 216_22855_49631\n",
      "Added COLMAP data to 216_22856_49632\n",
      "Removed background from images in 216_22856_49632\n",
      "Added COLMAP data to 216_22857_49633\n",
      "Removed background from images in 216_22857_49633\n",
      "Added COLMAP data to 216_22858_49634\n",
      "Removed background from images in 216_22858_49634\n",
      "Added COLMAP data to 216_22859_49635\n",
      "Removed background from images in 216_22859_49635\n",
      "Added COLMAP data to 216_22860_49636\n",
      "Removed background from images in 216_22860_49636\n",
      "Added COLMAP data to 216_22861_49637\n",
      "Removed background from images in 216_22861_49637\n",
      "Added COLMAP data to 216_22862_49638\n",
      "Removed background from images in 216_22862_49638\n",
      "Added COLMAP data to 216_22866_49900\n",
      "Removed background from images in 216_22866_49900\n",
      "Added COLMAP data to 216_22867_49765\n",
      "Removed background from images in 216_22867_49765\n",
      "Added COLMAP data to 216_22871_50171\n",
      "Removed background from images in 216_22871_50171\n",
      "Added COLMAP data to 235_24639_51669\n",
      "Removed background from images in 235_24639_51669\n",
      "Added COLMAP data to 235_24641_51707\n",
      "Removed background from images in 235_24641_51707\n",
      "Added COLMAP data to 244_25993_51715\n",
      "Removed background from images in 244_25993_51715\n",
      "Added COLMAP data to 244_25997_52016\n",
      "Removed background from images in 244_25997_52016\n",
      "Added COLMAP data to 250_26738_53523\n",
      "Removed background from images in 250_26738_53523\n",
      "Added COLMAP data to 250_26741_53521\n",
      "Removed background from images in 250_26741_53521\n",
      "Added COLMAP data to 250_26744_53526\n",
      "Removed background from images in 250_26744_53526\n",
      "Added COLMAP data to 250_26746_53530\n",
      "Removed background from images in 250_26746_53530\n",
      "Added COLMAP data to 250_26747_53540\n",
      "Removed background from images in 250_26747_53540\n",
      "Added COLMAP data to 250_26749_52968\n",
      "Removed background from images in 250_26749_52968\n",
      "Could not find 250_26762_54259\n",
      "Could not find 250_26764_54264\n",
      "Could not find 250_26765_54265\n",
      "Could not find 250_26767_54267\n",
      "Could not find 250_26768_54268\n",
      "Could not find 250_26770_54395\n",
      "Could not find 250_26771_55177\n",
      "Could not find 250_26774_54516\n",
      "Could not find 250_26775_55176\n",
      "Could not find 250_26776_55178\n",
      "Could not find 250_26779_55023\n",
      "Could not find 250_26806_55292\n",
      "Could not find 250_26807_55293\n",
      "Could not find 250_26808_55348\n",
      "Could not find 250_26810_55497\n",
      "Could not find 268_28455_57205\n",
      "Could not find 268_28467_57277\n",
      "Could not find 268_28507_57781\n",
      "Could not find 268_28513_58093\n",
      "Could not find 286_30158_58343\n",
      "Could not find 286_30158_58457\n",
      "Could not find 286_30159_58332\n",
      "Could not find 286_30163_58519\n",
      "Could not find 286_30164_59371\n",
      "Could not find 286_30165_59425\n",
      "Could not find 286_30167_59426\n",
      "Could not find 286_30168_59427\n",
      "Could not find 286_30169_59428\n",
      "Could not find 286_30170_59429\n",
      "Could not find 286_30171_59430\n",
      "Could not find 286_30172_59431\n",
      "Could not find 286_30173_59432\n",
      "Could not find 286_30174_59433\n",
      "Could not find 286_30175_59434\n",
      "Could not find 286_30176_59453\n",
      "Could not find 286_30177_59454\n",
      "Could not find 286_30178_59455\n",
      "Could not find 286_30179_59456\n",
      "Could not find 286_30180_59457\n",
      "Could not find 304_31872_60092\n",
      "Could not find 304_31873_60475\n",
      "Could not find 304_31875_60474\n",
      "Could not find 304_31876_60476\n",
      "Could not find 304_31877_60477\n",
      "Could not find 304_31878_60478\n",
      "Could not find 304_31880_60480\n",
      "Could not find 304_31881_60481\n",
      "Could not find 304_31882_60482\n",
      "Could not find 304_31883_60483\n",
      "Could not find 304_31884_60484\n",
      "Could not find 304_31885_60485\n",
      "Could not find 304_31886_60486\n",
      "Could not find 304_31887_60487\n",
      "Could not find 304_31888_60537\n",
      "Could not find 304_31892_61383\n",
      "Could not find 336_34793_62459\n",
      "Could not find 336_34794_62331\n",
      "Could not find 336_34812_62915\n",
      "Could not find 336_34816_63355\n",
      "Could not find 336_34817_63026\n",
      "Could not find 336_34822_63393\n",
      "Could not find 336_34823_63564\n",
      "Could not find 336_34831_63538\n",
      "Could not find 336_34836_63641\n",
      "Could not find 340_35384_65209\n",
      "Could not find 340_35389_65203\n",
      "Could not find 344_35892_65885\n",
      "Could not find 344_35897_66006\n",
      "Could not find 344_35901_65891\n",
      "Could not find 344_35903_65708\n",
      "Could not find 344_35905_66057\n",
      "Could not find 344_35912_66260\n",
      "Could not find 344_35916_66357\n",
      "Could not find 344_35947_66617\n",
      "Could not find 344_35948_66633\n",
      "Could not find 349_36502_68516\n",
      "Could not find 349_36526_68615\n",
      "Could not find 349_36559_68589\n",
      "Could not find 349_36568_68004\n",
      "Could not find 349_36579_68955\n",
      "Could not find 408_55392_106193\n",
      "Could not find 408_55514_107143\n",
      "Could not find 411_55943_107811\n",
      "Could not find 411_55961_107847\n",
      "Could not find 411_55970_107894\n",
      "Could not find 411_55980_108041\n",
      "Could not find 411_56003_108198\n",
      "Could not find 411_56017_108225\n",
      "Could not find 411_56028_108255\n",
      "Could not find 411_56031_108316\n",
      "Could not find 411_56055_108436\n",
      "Could not find 411_56063_108480\n",
      "Could not find 411_56064_108483\n",
      "Could not find 411_56066_108514\n",
      "Could not find 411_56072_108554\n",
      "Could not find 411_56077_108567\n",
      "Could not find 413_56483_109014\n",
      "Could not find 413_56495_109077\n",
      "Could not find 413_56508_109210\n",
      "Could not find 413_56510_109180\n",
      "Could not find 415_57031_109552\n",
      "Could not find 415_57040_109604\n",
      "Could not find 415_57123_110212\n",
      "Could not find 415_57126_110182\n",
      "Could not find 415_57127_110193\n",
      "Could not find 415_57128_110231\n",
      "Could not find 415_57131_110216\n",
      "Could not find 415_57132_110203\n",
      "Could not find 415_57135_110197\n",
      "Could not find 415_57139_110204\n",
      "Could not find 415_57140_110207\n",
      "Could not find 415_57142_110210\n",
      "Could not find 415_57145_110215\n",
      "Could not find 415_57149_110220\n",
      "Could not find 415_57151_110224\n",
      "Could not find 415_57152_110225\n",
      "Could not find 415_57153_110227\n",
      "Could not find 415_57154_110228\n",
      "Could not find 415_57155_110229\n",
      "Could not find 415_57156_110230\n",
      "Could not find 415_57162_110256\n",
      "Could not find 415_57163_110267\n",
      "Could not find 415_57164_110268\n",
      "Could not find 415_57180_110462\n",
      "Could not find 415_57185_110493\n",
      "Could not find 415_57187_110492\n",
      "Could not find 415_57190_110494\n",
      "Could not find 415_57191_110496\n",
      "Could not find 417_57567_110737\n",
      "Could not find 417_57576_110766\n",
      "Could not find 417_57580_110842\n",
      "Could not find 417_57585_110627\n",
      "Could not find 417_57589_110770\n",
      "Could not find 417_57591_110844\n",
      "Could not find 417_57592_110774\n",
      "Could not find 417_57593_110775\n",
      "Could not find 417_57594_110776\n",
      "Could not find 417_57599_110847\n",
      "Could not find 417_57602_110861\n",
      "Could not find 417_57603_110852\n",
      "Could not find 417_57612_110875\n",
      "Could not find 417_57631_110999\n",
      "Could not find 417_57649_111097\n",
      "Could not find 417_57711_111355\n",
      "Could not find 417_57712_111316\n",
      "Could not find 417_57716_111321\n",
      "Could not find 417_57717_111322\n",
      "Could not find 417_57727_111334\n",
      "Could not find 417_57728_111393\n",
      "Could not find 417_57730_111337\n",
      "Could not find 417_57732_111339\n",
      "Could not find 417_57734_111341\n",
      "Could not find 417_57740_111378\n",
      "Could not find 417_57746_111353\n",
      "Could not find 417_57776_111531\n",
      "Could not find 417_57803_111610\n",
      "Could not find 417_57844_111777\n",
      "Could not find 421_58368_112547\n",
      "Could not find 421_58375_112450\n",
      "Could not find 421_58385_112527\n",
      "Could not find 421_58389_112533\n",
      "Could not find 421_58395_112539\n",
      "Could not find 421_58396_112540\n",
      "Could not find 421_58398_112543\n",
      "Could not find 421_58399_112544\n",
      "Could not find 421_58400_112545\n",
      "Could not find 421_58401_112546\n",
      "Could not find 421_58414_112560\n",
      "Could not find 421_58415_112561\n",
      "Could not find 421_58422_112570\n",
      "Could not find 421_58428_112592\n",
      "Could not find 421_58448_112675\n",
      "Could not find 421_58453_112679\n",
      "Could not find 421_58481_112925\n",
      "Could not find 423_58828_113391\n",
      "Could not find 423_58839_113399\n",
      "Could not find 423_58880_113838\n",
      "Could not find 423_58894_113885\n",
      "Could not find 423_58949_114399\n",
      "Could not find 423_58957_114450\n",
      "Could not find 425_59335_114809\n",
      "Could not find 426_59712_115788\n",
      "Could not find 427_59883_115498\n",
      "Could not find 427_59892_115555\n",
      "Could not find 427_59907_115784\n",
      "Could not find 427_59914_115791\n",
      "Could not find 427_59916_115772\n",
      "Could not find 427_59918_115773\n",
      "Could not find 427_59919_115775\n",
      "Could not find 427_59920_115776\n",
      "Could not find 427_59921_115777\n",
      "Could not find 427_59941_115914\n",
      "Added COLMAP data to 427_59989_115990\n",
      "Removed background from images in 427_59989_115990\n",
      "Added COLMAP data to 427_60012_116112\n",
      "Removed background from images in 427_60012_116112\n",
      "Added COLMAP data to 427_60021_116224\n",
      "Removed background from images in 427_60021_116224\n",
      "Added COLMAP data to 429_60327_116727\n",
      "Removed background from images in 429_60327_116727\n",
      "Added COLMAP data to 429_60353_116942\n",
      "Removed background from images in 429_60353_116942\n",
      "Added COLMAP data to 429_60354_116944\n",
      "Removed background from images in 429_60354_116944\n",
      "Added COLMAP data to 429_60355_117003\n",
      "Removed background from images in 429_60355_117003\n",
      "Added COLMAP data to 429_60360_116956\n",
      "Removed background from images in 429_60360_116956\n",
      "Added COLMAP data to 429_60361_116957\n",
      "Removed background from images in 429_60361_116957\n",
      "Added COLMAP data to 429_60365_116961\n",
      "Removed background from images in 429_60365_116961\n",
      "Added COLMAP data to 429_60367_116963\n",
      "Removed background from images in 429_60367_116963\n",
      "Added COLMAP data to 429_60368_116964\n",
      "Removed background from images in 429_60368_116964\n",
      "Added COLMAP data to 429_60372_116968\n",
      "Removed background from images in 429_60372_116968\n",
      "Added COLMAP data to 429_60373_116969\n",
      "Removed background from images in 429_60373_116969\n",
      "Added COLMAP data to 429_60388_117059\n",
      "Removed background from images in 429_60388_117059\n",
      "Added COLMAP data to 429_60395_117232\n",
      "Removed background from images in 429_60395_117232\n",
      "Added COLMAP data to 429_60420_117369\n",
      "Removed background from images in 429_60420_117369\n",
      "Added COLMAP data to 429_60423_117417\n",
      "Removed background from images in 429_60423_117417\n",
      "Added COLMAP data to 429_60424_117419\n",
      "Removed background from images in 429_60424_117419\n",
      "Added COLMAP data to 429_60427_117424\n",
      "Removed background from images in 429_60427_117424\n",
      "Added COLMAP data to 429_60515_117738\n",
      "Removed background from images in 429_60515_117738\n",
      "Added COLMAP data to 429_60517_117787\n",
      "Removed background from images in 429_60517_117787\n",
      "Added COLMAP data to 429_60519_117794\n",
      "Removed background from images in 429_60519_117794\n",
      "Added COLMAP data to 431_60834_118050\n",
      "Removed background from images in 431_60834_118050\n",
      "Added COLMAP data to 431_60835_118048\n",
      "Removed background from images in 431_60835_118048\n",
      "Added COLMAP data to 431_60836_118051\n",
      "Removed background from images in 431_60836_118051\n",
      "Added COLMAP data to 431_60873_118371\n",
      "Removed background from images in 431_60873_118371\n",
      "Added COLMAP data to 431_60877_118374\n",
      "Removed background from images in 431_60877_118374\n",
      "Added COLMAP data to 431_60883_118387\n",
      "Removed background from images in 431_60883_118387\n",
      "Added COLMAP data to 431_60884_118389\n",
      "Removed background from images in 431_60884_118389\n",
      "Added COLMAP data to 431_60885_118390\n",
      "Removed background from images in 431_60885_118390\n",
      "Added COLMAP data to 431_60887_118392\n",
      "Removed background from images in 431_60887_118392\n",
      "Added COLMAP data to 431_60889_118394\n",
      "Removed background from images in 431_60889_118394\n",
      "Added COLMAP data to 431_60892_118397\n",
      "Removed background from images in 431_60892_118397\n",
      "Added COLMAP data to 431_60893_118398\n",
      "Removed background from images in 431_60893_118398\n",
      "Added COLMAP data to 431_60923_118547\n",
      "Removed background from images in 431_60923_118547\n",
      "Added COLMAP data to 431_60932_118718\n",
      "Removed background from images in 431_60932_118718\n",
      "Added COLMAP data to 431_60943_118736\n",
      "Removed background from images in 431_60943_118736\n",
      "Added COLMAP data to 431_60944_118757\n",
      "Removed background from images in 431_60944_118757\n",
      "Added COLMAP data to 431_60945_118758\n",
      "Removed background from images in 431_60945_118758\n",
      "Added COLMAP data to 431_60948_118761\n",
      "Removed background from images in 431_60948_118761\n",
      "Added COLMAP data to 431_60950_118763\n",
      "Removed background from images in 431_60950_118763\n",
      "Added COLMAP data to 431_60951_118764\n",
      "Removed background from images in 431_60951_118764\n",
      "Added COLMAP data to 431_60952_118765\n",
      "Removed background from images in 431_60952_118765\n",
      "Added COLMAP data to 431_60963_118818\n",
      "Removed background from images in 431_60963_118818\n",
      "Added COLMAP data to 431_60980_119093\n",
      "Removed background from images in 431_60980_119093\n",
      "Added COLMAP data to 431_60998_119136\n",
      "Removed background from images in 431_60998_119136\n",
      "Added COLMAP data to 431_61002_119201\n",
      "Removed background from images in 431_61002_119201\n",
      "Added COLMAP data to 433_61365_119703\n",
      "Removed background from images in 433_61365_119703\n",
      "Added COLMAP data to 433_61371_119784\n",
      "Removed background from images in 433_61371_119784\n",
      "Added COLMAP data to 433_61372_119852\n",
      "Removed background from images in 433_61372_119852\n",
      "Added COLMAP data to 433_61378_119876\n",
      "Removed background from images in 433_61378_119876\n",
      "Added COLMAP data to 433_61409_120035\n",
      "Removed background from images in 433_61409_120035\n",
      "Added COLMAP data to 433_61417_120045\n",
      "Removed background from images in 433_61417_120045\n",
      "Added COLMAP data to 433_61489_120178\n",
      "Removed background from images in 433_61489_120178\n",
      "Added COLMAP data to 433_61490_120180\n",
      "Removed background from images in 433_61490_120180\n",
      "Added COLMAP data to 433_61495_120185\n",
      "Removed background from images in 433_61495_120185\n",
      "Added COLMAP data to 433_61496_120188\n",
      "Removed background from images in 433_61496_120188\n",
      "Added COLMAP data to 433_61497_120187\n",
      "Removed background from images in 433_61497_120187\n",
      "Added COLMAP data to 433_61502_120193\n",
      "Removed background from images in 433_61502_120193\n",
      "Added COLMAP data to 433_61507_120199\n",
      "Removed background from images in 433_61507_120199\n",
      "Added COLMAP data to 433_61509_120201\n",
      "Removed background from images in 433_61509_120201\n",
      "Added COLMAP data to 433_61514_120207\n",
      "Removed background from images in 433_61514_120207\n",
      "Added COLMAP data to 433_61517_120210\n",
      "Removed background from images in 433_61517_120210\n",
      "Added COLMAP data to 433_61523_120300\n",
      "Removed background from images in 433_61523_120300\n",
      "Added COLMAP data to 433_61532_120301\n",
      "Removed background from images in 433_61532_120301\n",
      "Added COLMAP data to 433_61534_120303\n",
      "Removed background from images in 433_61534_120303\n",
      "Added COLMAP data to 433_61535_120304\n",
      "Removed background from images in 433_61535_120304\n",
      "Could not find 433_61536_120305\n",
      "Could not find 433_61556_120387\n",
      "Could not find 435_61821_120873\n",
      "Could not find 435_61832_120902\n",
      "Could not find 435_61833_120961\n",
      "Could not find 435_61862_121151\n",
      "Could not find 435_61895_121413\n",
      "Could not find 435_61899_121439\n",
      "Could not find 437_62335_122250\n",
      "Could not find 437_62405_122559\n",
      "Could not find 437_62459_122688\n",
      "Could not find 437_62476_122841\n",
      "Could not find 437_62483_122881\n",
      "Could not find 437_62492_122961\n",
      "Could not find 437_62520_123333\n",
      "Could not find 437_62521_123329\n",
      "Could not find 437_62523_123349\n",
      "Could not find 437_62531_123471\n",
      "Could not find 437_62533_123474\n",
      "Could not find 437_62538_123480\n",
      "Could not find 439_62823_123839\n",
      "Could not find 439_62838_123972\n",
      "Could not find 439_62852_124096\n",
      "Could not find 439_62855_124100\n",
      "Could not find 439_62856_124101\n",
      "Could not find 439_62863_124108\n",
      "Could not find 439_62865_124110\n",
      "Could not find 439_62868_124113\n",
      "Could not find 439_62869_124114\n",
      "Could not find 439_62871_124116\n",
      "Could not find 439_62873_124118\n",
      "Could not find 439_62874_124120\n",
      "Could not find 439_62899_124367\n",
      "Could not find 439_62901_124386\n",
      "Could not find 439_62905_124433\n",
      "Could not find 439_62982_124683\n",
      "Could not find 439_62990_124813\n",
      "Could not find 441_63117_125248\n",
      "Could not find 441_63133_125437\n",
      "Could not find 443_63518_125712\n",
      "Could not find 443_63527_125841\n",
      "Could not find 443_63534_125919\n",
      "Could not find 462_65350_128180\n",
      "Could not find 462_65358_128182\n",
      "Could not find 462_65381_128274\n",
      "Could not find 462_65388_128415\n",
      "Could not find 462_65389_128323\n",
      "Could not find 462_65391_128383\n",
      "Could not find 462_65392_128440\n",
      "Could not find 462_65394_128333\n",
      "Could not find 462_65395_128433\n",
      "Could not find 462_65396_128412\n",
      "Could not find 462_65398_128428\n",
      "Could not find 462_65399_128447\n",
      "Could not find 462_65404_128421\n",
      "Could not find 462_65408_128443\n",
      "Could not find 462_65409_128452\n",
      "Could not find 464_65742_128863\n",
      "Could not find 464_65763_129220\n",
      "Could not find 464_65765_129282\n",
      "Could not find 464_65774_129374\n",
      "Could not find 464_65783_129401\n",
      "Could not find 464_65784_129407\n",
      "Could not find 469_66144_129937\n",
      "Could not find 469_66154_130018\n",
      "Could not find 469_66159_130067\n",
      "Could not find 469_66167_130133\n",
      "Could not find 469_66168_130125\n",
      "Could not find 469_66170_130199\n",
      "Could not find 469_66171_130134\n",
      "Could not find 469_66174_130141\n",
      "Could not find 469_66175_130221\n",
      "Could not find 469_66193_130547\n",
      "Could not find 469_66204_130711\n",
      "Could not find 471_66544_130959\n",
      "Could not find 471_66564_130866\n",
      "Could not find 471_66566_130944\n",
      "Could not find 471_66568_130948\n",
      "Could not find 471_66570_130947\n",
      "Could not find 471_66571_130950\n",
      "Could not find 471_66572_130952\n",
      "Could not find 471_66573_130958\n",
      "Could not find 471_66597_131102\n",
      "Could not find 471_66620_131249\n",
      "Could not find 471_66626_131248\n",
      "Could not find 471_66627_131250\n",
      "Could not find 473_66955_131655\n",
      "Could not find 473_66956_131589\n",
      "Could not find 476_67451_132322\n",
      "Could not find 478_67922_132683\n",
      "Could not find 478_67952_133183\n",
      "Could not find 478_67961_133250\n",
      "Could not find 478_67977_133282\n",
      "Could not find 478_67981_133284\n",
      "Could not find 478_67982_133286\n",
      "Could not find 478_67998_133378\n",
      "Could not find 478_68003_133384\n",
      "Could not find 478_68007_133389\n",
      "Could not find 478_68011_133393\n",
      "Could not find 481_68710_133694\n",
      "Could not find 481_68714_133660\n",
      "Could not find 481_68715_133661\n",
      "Could not find 481_68717_133663\n",
      "Could not find 481_68723_133699\n",
      "Could not find 481_68724_133717\n",
      "Could not find 481_68731_133705\n",
      "Could not find 481_68775_134176\n",
      "Could not find 481_68778_134219\n",
      "Could not find 481_68784_134257\n",
      "Could not find 481_68787_134260\n",
      "Could not find 481_68788_134262\n",
      "Could not find 481_68792_134274\n",
      "Could not find 481_68796_134275\n",
      "Could not find 481_68797_134294\n",
      "Could not find 481_68803_134306\n",
      "Could not find 481_68824_134715\n",
      "Could not find 481_68831_134719\n",
      "Could not find 481_68840_134912\n",
      "Could not find 483_69190_135212\n",
      "Could not find 483_69200_135538\n",
      "Could not find 483_69207_135609\n",
      "Could not find 491_70237_136049\n",
      "Could not find 491_70245_136467\n",
      "Could not find 491_70263_136778\n",
      "Could not find 491_70265_136782\n",
      "Could not find 491_70268_136787\n",
      "Could not find 491_70269_136788\n",
      "Could not find 491_70274_136797\n",
      "Could not find 491_70278_136803\n",
      "Could not find 491_70279_136804\n",
      "Could not find 491_70280_136805\n",
      "Could not find 491_70283_136808\n",
      "Could not find 491_70285_136810\n",
      "Could not find 491_70290_136818\n",
      "Could not find 491_70291_136823\n",
      "Could not find 491_70292_136820\n",
      "Could not find 491_70293_136822\n",
      "Could not find 494_70801_138115\n",
      "Could not find 494_70822_138336\n",
      "Could not find 494_70832_138520\n",
      "Could not find 494_70843_138559\n",
      "Could not find 494_70850_138568\n",
      "Could not find 497_71356_138882\n",
      "Could not find 497_71367_139191\n",
      "Could not find 497_71368_139133\n",
      "Could not find 500_71834_140015\n",
      "Could not find 503_72340_140929\n",
      "Could not find 505_72712_141544\n",
      "Could not find 505_72714_141560\n",
      "Could not find 505_72717_141569\n",
      "Could not find 505_72742_142191\n",
      "Could not find 505_72776_142381\n",
      "Could not find 507_73112_142558\n",
      "Could not find 513_73556_143803\n",
      "Could not find 513_73568_144138\n",
      "Could not find 516_74046_144532\n",
      "Could not find 516_74071_144574\n",
      "Could not find 519_74488_144698\n",
      "Could not find 519_74496_144736\n",
      "Could not find 519_74501_144891\n",
      "Could not find 519_74518_145083\n",
      "Could not find 519_74526_145191\n",
      "Could not find 522_74969_145521\n",
      "Could not find 522_74987_145965\n",
      "Could not find 522_74995_146028\n",
      "Could not find 522_75006_146164\n",
      "Could not find 522_75012_146213\n",
      "Could not find 522_75065_146868\n",
      "Could not find 528_76479_147703\n",
      "Could not find 528_76481_147781\n",
      "Could not find 528_76490_147741\n",
      "Could not find 528_76508_147795\n",
      "Could not find 528_76522_148065\n",
      "Could not find 533_77227_149577\n",
      "Could not find 533_77260_150110\n",
      "Could not find 533_77313_150397\n",
      "Could not find 533_77316_150415\n",
      "Could not find 533_77322_150675\n",
      "Could not find 536_77980_150844\n",
      "Could not find 536_77983_150920\n",
      "Could not find 539_78730_152496\n",
      "Could not find 539_78741_152618\n",
      "Could not find 539_78759_153356\n",
      "Could not find 539_78777_154040\n",
      "Could not find 539_78780_154075\n",
      "Could not find 554_79504_154519\n",
      "Could not find 554_79506_154211\n",
      "Could not find 554_79561_156370\n",
      "Could not find 554_79564_156510\n",
      "Could not find 554_79597_157221\n",
      "Could not find 557_80269_157919\n",
      "Could not find 564_81541_160375\n",
      "Could not find 564_81547_160465\n",
      "Could not find 564_81549_160397\n",
      "Could not find 564_81568_161173\n",
      "Could not find 567_82268_162289\n",
      "Could not find 567_82276_162311\n",
      "Could not find 567_82286_162464\n",
      "Could not find 570_83027_162641\n",
      "Could not find 570_83032_162650\n",
      "Could not find 570_83077_163199\n",
      "Could not find 570_83084_163208\n",
      "Could not find 570_83088_163219\n",
      "Could not find 572_83651_164957\n",
      "Could not find 572_83658_164911\n",
      "Could not find 572_83673_165209\n",
      "Could not find 572_83688_165407\n",
      "Could not find 572_83692_165445\n",
      "Could not find 572_83694_165428\n",
      "Could not find 572_83695_165429\n",
      "Could not find 572_83696_165431\n",
      "Could not find 572_83698_165433\n",
      "Could not find 572_83708_165452\n",
      "Could not find 572_83712_165490\n",
      "Could not find 574_84223_165812\n",
      "Could not find 574_84251_166332\n",
      "Could not find 576_84833_166716\n",
      "Could not find 576_84834_166729\n",
      "Could not find 576_84835_166737\n",
      "Could not find 576_84836_166739\n",
      "Could not find 576_84838_166750\n",
      "Could not find 576_84839_166751\n",
      "Could not find 576_84841_166758\n",
      "Could not find 576_84844_166761\n",
      "Could not find 576_84850_166771\n",
      "Could not find 576_84898_167564\n",
      "Could not find 576_84899_167567\n",
      "Could not find 576_84900_167571\n",
      "Could not find 576_84901_167599\n",
      "Could not find 576_84902_167574\n",
      "Could not find 576_84903_167583\n",
      "Could not find 576_84906_167584\n",
      "Could not find 576_84913_167604\n",
      "Could not find 578_85433_168116\n",
      "Could not find 578_85450_168276\n",
      "Could not find 580_86059_169410\n",
      "Could not find 580_86082_169785\n",
      "Could not find 580_86089_170092\n",
      "Could not find 582_86625_170421\n",
      "Could not find 582_86637_170961\n",
      "Could not find 582_86643_171027\n",
      "Could not find 584_87224_172422\n",
      "Could not find 587_87863_173253\n",
      "Could not find 590_88779_174477\n",
      "Could not find 590_88782_174618\n",
      "Could not find 590_88789_174496\n",
      "Could not find 590_88795_174679\n",
      "Could not find 590_88804_174817\n",
      "Could not find 590_88811_174914\n",
      "Could not find 590_88824_174946\n",
      "Could not find 590_88831_175196\n",
      "Could not find 590_88840_175544\n",
      "Could not find 590_88846_175978\n",
      "Could not find 590_88863_176085\n",
      "Could not find 590_88875_176277\n",
      "Could not find 590_88949_178245\n",
      "Could not find 590_88950_178272\n",
      "Could not find 590_88970_178685\n",
      "Could not find 593_89932_178896\n",
      "Could not find 593_89950_179389\n",
      "Could not find 596_91093_180551\n",
      "Could not find 596_91110_180617\n",
      "Could not find 596_91115_180802\n",
      "Could not find 596_91118_180844\n",
      "Could not find 599_92297_183310\n",
      "Could not find 599_92298_183457\n",
      "Could not find 599_92317_183728\n",
      "Could not find 599_92345_184298\n",
      "Could not find 602_93377_184938\n",
      "Could not find 602_93389_185075\n",
      "Could not find 602_93391_185195\n",
      "Could not find 602_93419_185626\n",
      "Could not find 602_93426_185637\n",
      "Could not find 602_93434_185698\n",
      "Could not find 602_93436_185822\n",
      "Could not find 602_93451_186863\n",
      "Could not find 602_93495_186852\n",
      "Could not find 602_93534_187057\n",
      "Could not find 602_93535_187060\n",
      "Could not find 605_94545_187421\n",
      "Could not find 605_94593_188121\n",
      "Could not find 605_94631_188610\n",
      "Could not find 605_94645_188712\n",
      "Could not find 605_94712_189407\n",
      "Could not find 605_94717_189413\n",
      "Could not find 607_95430_190076\n",
      "Could not find 607_95465_190320\n",
      "Could not find 609_96424_192306\n",
      "Could not find 609_96443_192320\n",
      "Could not find 609_96489_192601\n",
      "Could not find 609_96514_192756\n",
      "Could not find 611_97315_193434\n",
      "Could not find 613_98140_195489\n",
      "Could not find 613_98159_195624\n",
      "Could not find 613_98189_195690\n",
      "Could not find 613_98197_195828\n",
      "Could not find 613_98211_195756\n",
      "Could not find 613_98242_196036\n",
      "Could not find 613_98275_196061\n",
      "Could not find 613_98281_196128\n",
      "Could not find 613_98296_196298\n",
      "Could not find 613_98317_196343\n",
      "Could not find 615_99087_197548\n",
      "Could not find 615_99120_197713\n",
      "Could not find 615_99151_197824\n",
      "Could not find 615_99185_198005\n",
      "Could not find 615_99190_197972\n",
      "Could not find 615_99211_198180\n",
      "Could not find 617_100120_199545\n",
      "Could not find 617_99977_199063\n",
      "Could not find 619_100826_199984\n",
      "Could not find 619_100909_200299\n",
      "Could not find 619_100913_200311\n",
      "Could not find 619_101012_200575\n",
      "Could not find 621_101818_202761\n",
      "Could not find 623_102790_204985\n",
      "Could not find 625_103558_206621\n",
      "Could not find 625_103564_206653\n",
      "Added COLMAP data to 79_8251_17496\n",
      "Removed background from images in 79_8251_17496\n",
      "Generating GS for 433_61495_120185\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61495_120185\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0252646, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:36, 12.58it/s, Loss=0.0252646, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:36, 12.58it/s, Loss=0.0220896, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:17, 13.19it/s, Loss=0.0220896, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:17, 13.19it/s, Loss=0.0200368, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:08, 13.49it/s, Loss=0.0200368, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:08, 13.49it/s, Loss=0.0253005, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:09, 13.42it/s, Loss=0.0253005, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:09, 13.42it/s, Loss=0.0198009, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:09, 13.40it/s, Loss=0.0198009, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:09, 13.40it/s, Loss=0.0218174, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:07, 13.45it/s, Loss=0.0218174, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:07, 13.45it/s, Loss=0.0170687, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:03, 13.57it/s, Loss=0.0170687, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:03, 13.57it/s, Loss=0.0206295, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<06:04, 13.51it/s, Loss=0.0206295, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:04, 13.51it/s, Loss=0.0201465, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<06:04, 13.46it/s, Loss=0.0201465, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:04, 13.46it/s, Loss=0.0190175, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<06:02, 13.52it/s, Loss=0.0190175, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:02, 13.52it/s, Loss=0.0164393, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:00, 13.56it/s, Loss=0.0164393, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:00, 13.56it/s, Loss=0.0185457, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:08<06:01, 13.50it/s, Loss=0.0185457, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:01, 13.50it/s, Loss=0.0202872, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<06:04, 13.38it/s, Loss=0.0202872, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:04, 13.38it/s, Loss=0.0161673, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<06:03, 13.37it/s, Loss=0.0161673, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:03, 13.37it/s, Loss=0.0170418, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:04, 13.32it/s, Loss=0.0170418, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:04, 13.32it/s, Loss=0.0152586, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:11<06:01, 13.40it/s, Loss=0.0152586, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:01, 13.40it/s, Loss=0.0136691, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:12<05:58, 13.47it/s, Loss=0.0136691, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<05:58, 13.47it/s, Loss=0.0156317, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<05:54, 13.62it/s, Loss=0.0156317, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<05:54, 13.62it/s, Loss=0.0195319, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<05:54, 13.56it/s, Loss=0.0195319, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<05:54, 13.56it/s, Loss=0.0203666, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:14<05:56, 13.46it/s, Loss=0.0203666, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:56, 13.46it/s, Loss=0.0175712, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:24, 14.76it/s, Loss=0.0175712, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:24, 14.76it/s, Loss=0.0172818, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:15<04:56, 16.11it/s, Loss=0.0172818, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<04:56, 16.11it/s, Loss=0.0164262, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:39, 17.10it/s, Loss=0.0164262, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:39, 17.10it/s, Loss=0.0196978, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:16<04:26, 17.87it/s, Loss=0.0196978, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:26, 17.87it/s, Loss=0.0171052, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:16, 18.50it/s, Loss=0.0171052, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:16, 18.50it/s, Loss=0.0193031, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:17<04:12, 18.81it/s, Loss=0.0193031, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:12, 18.81it/s, Loss=0.0166812, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:09, 18.93it/s, Loss=0.0166812, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:09, 18.93it/s, Loss=0.0180939, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:18<04:06, 19.17it/s, Loss=0.0180939, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:06, 19.17it/s, Loss=0.0170127, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:03, 19.35it/s, Loss=0.0170127, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:03, 19.35it/s, Loss=0.0193169, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:19<04:00, 19.52it/s, Loss=0.0193169, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [433,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [62,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<05:13, 14.99it/s, Loss=0.0193169, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 431_60835_118048\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60835_118048\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0533677, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   0%|          | 10/5000 [00:00<05:35, 14.90it/s, Loss=0.0533677, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   0%|          | 10/5000 [00:01<05:35, 14.90it/s, Loss=0.0505448, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   0%|          | 20/5000 [00:01<05:11, 15.98it/s, Loss=0.0505448, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   0%|          | 20/5000 [00:01<05:11, 15.98it/s, Loss=0.0400599, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 30/5000 [00:01<05:03, 16.38it/s, Loss=0.0400599, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 30/5000 [00:02<05:03, 16.38it/s, Loss=0.0547966, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 40/5000 [00:02<04:58, 16.61it/s, Loss=0.0547966, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 40/5000 [00:03<04:58, 16.61it/s, Loss=0.0321801, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 50/5000 [00:03<04:57, 16.66it/s, Loss=0.0321801, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 50/5000 [00:03<04:57, 16.66it/s, Loss=0.0417678, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 60/5000 [00:03<04:51, 16.96it/s, Loss=0.0417678, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|          | 60/5000 [00:04<04:51, 16.96it/s, Loss=0.0281207, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|▏         | 70/5000 [00:04<04:48, 17.08it/s, Loss=0.0281207, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   1%|▏         | 70/5000 [00:04<04:48, 17.08it/s, Loss=0.0301577, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 80/5000 [00:04<04:48, 17.07it/s, Loss=0.0301577, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<04:48, 17.07it/s, Loss=0.0314430, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 90/5000 [00:05<04:45, 17.21it/s, Loss=0.0314430, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 90/5000 [00:05<04:45, 17.21it/s, Loss=0.0242251, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 100/5000 [00:05<04:42, 17.38it/s, Loss=0.0242251, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 100/5000 [00:06<04:42, 17.38it/s, Loss=0.0225429, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 110/5000 [00:06<04:47, 17.01it/s, Loss=0.0225429, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 110/5000 [00:07<04:47, 17.01it/s, Loss=0.0239634, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 120/5000 [00:07<04:43, 17.20it/s, Loss=0.0239634, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   2%|▏         | 120/5000 [00:07<04:43, 17.20it/s, Loss=0.0235896, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 130/5000 [00:07<04:40, 17.39it/s, Loss=0.0235896, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 130/5000 [00:08<04:40, 17.39it/s, Loss=0.0220574, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 140/5000 [00:08<04:42, 17.18it/s, Loss=0.0220574, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 140/5000 [00:08<04:42, 17.18it/s, Loss=0.0192080, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 150/5000 [00:08<04:40, 17.30it/s, Loss=0.0192080, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 150/5000 [00:09<04:40, 17.30it/s, Loss=0.0217504, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 160/5000 [00:09<04:41, 17.21it/s, Loss=0.0217504, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 160/5000 [00:09<04:41, 17.21it/s, Loss=0.0155453, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 170/5000 [00:09<04:36, 17.45it/s, Loss=0.0155453, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   3%|▎         | 170/5000 [00:10<04:36, 17.45it/s, Loss=0.0163054, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   4%|▎         | 180/5000 [00:10<04:38, 17.31it/s, Loss=0.0163054, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   4%|▎         | 180/5000 [00:11<04:38, 17.31it/s, Loss=0.0183395, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   4%|▍         | 190/5000 [00:11<04:36, 17.38it/s, Loss=0.0183395, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   4%|▍         | 190/5000 [00:11<04:36, 17.38it/s, Loss=0.0197834, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "Training progress:   4%|▍         | 200/5000 [00:11<04:41, 17.05it/s, Loss=0.0197834, Depth Loss=0.0000000, Number Gaussians=517631]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [475,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   4%|▍         | 200/5000 [00:11<04:43, 16.92it/s, Loss=0.0197834, Depth Loss=0.0000000, Number Gaussians=517631]\n",
      "\n",
      "Generating GS for 431_60873_118371\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60873_118371\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0380080, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:42, 12.39it/s, Loss=0.0380080, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:42, 12.39it/s, Loss=0.0337622, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:26, 12.89it/s, Loss=0.0337622, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:26, 12.89it/s, Loss=0.0314311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:17, 13.15it/s, Loss=0.0314311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:17, 13.15it/s, Loss=0.0559529, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:17, 13.13it/s, Loss=0.0559529, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:17, 13.13it/s, Loss=0.0311029, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:17, 13.11it/s, Loss=0.0311029, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:17, 13.11it/s, Loss=0.0335059, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:17, 13.09it/s, Loss=0.0335059, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:17, 13.09it/s, Loss=0.0315997, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:16, 13.09it/s, Loss=0.0315997, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:16, 13.09it/s, Loss=0.0289641, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:16, 13.08it/s, Loss=0.0289641, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:16, 13.08it/s, Loss=0.0362620, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<06:15, 13.09it/s, Loss=0.0362620, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:15, 13.09it/s, Loss=0.0272260, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<06:14, 13.07it/s, Loss=0.0272260, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:14, 13.07it/s, Loss=0.0275477, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:14, 13.07it/s, Loss=0.0275477, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:14, 13.07it/s, Loss=0.0268999, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:15, 13.01it/s, Loss=0.0268999, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:15, 13.01it/s, Loss=0.0228952, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<06:14, 13.02it/s, Loss=0.0228952, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:14, 13.02it/s, Loss=0.0318398, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<06:12, 13.04it/s, Loss=0.0318398, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:12, 13.04it/s, Loss=0.0266126, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:11, 13.05it/s, Loss=0.0266126, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:11, 13.05it/s, Loss=0.0349761, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:12, 12.99it/s, Loss=0.0349761, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:12, 12.99it/s, Loss=0.0416571, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:13, 12.94it/s, Loss=0.0416571, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:13, 12.94it/s, Loss=0.0296774, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<06:14, 12.86it/s, Loss=0.0296774, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<06:14, 12.86it/s, Loss=0.0263403, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<06:13, 12.88it/s, Loss=0.0263403, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:13, 12.88it/s, Loss=0.0401855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<06:11, 12.92it/s, Loss=0.0401855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<06:11, 12.92it/s, Loss=0.0267790, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:37, 14.18it/s, Loss=0.0267790, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:16<05:37, 14.18it/s, Loss=0.0432147, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<05:10, 15.39it/s, Loss=0.0432147, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<05:10, 15.39it/s, Loss=0.0221342, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:50, 16.43it/s, Loss=0.0221342, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:17<04:50, 16.43it/s, Loss=0.0508114, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:36, 17.21it/s, Loss=0.0508114, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:18<04:36, 17.21it/s, Loss=0.0298307, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:28, 17.67it/s, Loss=0.0298307, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:28, 17.67it/s, Loss=0.0227859, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:22, 18.07it/s, Loss=0.0227859, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:19<04:22, 18.07it/s, Loss=0.0279453, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:16, 18.43it/s, Loss=0.0279453, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:16, 18.43it/s, Loss=0.0413952, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:13, 18.58it/s, Loss=0.0413952, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:20<04:13, 18.58it/s, Loss=0.0225893, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:11, 18.74it/s, Loss=0.0225893, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:11, 18.74it/s, Loss=0.0224635, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<04:09, 18.80it/s, Loss=0.0224635, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [3,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [140,0,0], thread: [14,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<05:24, 14.49it/s, Loss=0.0224635, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 433_61534_120303\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61534_120303\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0366447, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:50, 10.62it/s, Loss=0.0366447, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:50, 10.62it/s, Loss=0.0335959, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:29, 11.08it/s, Loss=0.0335959, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:29, 11.08it/s, Loss=0.0397090, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:18, 11.33it/s, Loss=0.0397090, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:18, 11.33it/s, Loss=0.0377381, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:22, 11.21it/s, Loss=0.0377381, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:22, 11.21it/s, Loss=0.0332722, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<07:21, 11.20it/s, Loss=0.0332722, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<07:21, 11.20it/s, Loss=0.0376701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<07:29, 11.00it/s, Loss=0.0376701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<07:29, 11.00it/s, Loss=0.0273378, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:25, 11.06it/s, Loss=0.0273378, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:07<07:25, 11.06it/s, Loss=0.0225071, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<07:15, 11.30it/s, Loss=0.0225071, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:08<07:15, 11.30it/s, Loss=0.0327200, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<07:21, 11.12it/s, Loss=0.0327200, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:09<07:21, 11.12it/s, Loss=0.0325659, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:23, 11.05it/s, Loss=0.0325659, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:23, 11.05it/s, Loss=0.0297894, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<07:20, 11.10it/s, Loss=0.0297894, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<07:20, 11.10it/s, Loss=0.0284709, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<07:22, 11.02it/s, Loss=0.0284709, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:22, 11.02it/s, Loss=0.0328510, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<07:25, 10.94it/s, Loss=0.0328510, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:25, 10.94it/s, Loss=0.0321855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<07:21, 11.01it/s, Loss=0.0321855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:13<07:21, 11.01it/s, Loss=0.0353504, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<07:19, 11.04it/s, Loss=0.0353504, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:14<07:19, 11.04it/s, Loss=0.0282996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<07:15, 11.10it/s, Loss=0.0282996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:15<07:15, 11.10it/s, Loss=0.0365055, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<07:19, 10.99it/s, Loss=0.0365055, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:16<07:19, 10.99it/s, Loss=0.0339615, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<07:25, 10.82it/s, Loss=0.0339615, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:17<07:25, 10.82it/s, Loss=0.0323139, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:17<07:27, 10.75it/s, Loss=0.0323139, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:18<07:27, 10.75it/s, Loss=0.0242955, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:18<07:18, 10.95it/s, Loss=0.0242955, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:18<07:18, 10.95it/s, Loss=0.0346520, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:18<06:37, 12.05it/s, Loss=0.0346520, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:37, 12.05it/s, Loss=0.0342930, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:19<06:09, 12.92it/s, Loss=0.0342930, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:20<06:09, 12.92it/s, Loss=0.0319005, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:45, 13.81it/s, Loss=0.0319005, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:45, 13.81it/s, Loss=0.0276084, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:20<05:29, 14.43it/s, Loss=0.0276084, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:21<05:29, 14.43it/s, Loss=0.0287159, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:21<05:21, 14.78it/s, Loss=0.0287159, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:21<05:21, 14.78it/s, Loss=0.0267776, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:21<05:11, 15.21it/s, Loss=0.0267776, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:22<05:11, 15.21it/s, Loss=0.0273202, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:22<05:10, 15.26it/s, Loss=0.0273202, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:10, 15.26it/s, Loss=0.0293695, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:23<05:07, 15.34it/s, Loss=0.0293695, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:23<05:07, 15.34it/s, Loss=0.0281192, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:23<05:04, 15.46it/s, Loss=0.0281192, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:04, 15.46it/s, Loss=0.0229835, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:24<05:02, 15.55it/s, Loss=0.0229835, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:24<05:02, 15.55it/s, Loss=0.0269706, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:24<04:43, 16.57it/s, Loss=0.0269706, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:25<04:43, 16.57it/s, Loss=0.0335387, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:25<04:26, 17.57it/s, Loss=0.0335387, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:25<04:26, 17.57it/s, Loss=0.0309740, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:25<04:15, 18.28it/s, Loss=0.0309740, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:26<04:15, 18.28it/s, Loss=0.0278964, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:26<04:07, 18.83it/s, Loss=0.0278964, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:27<04:07, 18.83it/s, Loss=0.0282709, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:27<04:10, 18.59it/s, Loss=0.0282709, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:27<04:10, 18.59it/s, Loss=0.0299206, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:27<04:06, 18.84it/s, Loss=0.0299206, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:28<04:06, 18.84it/s, Loss=0.0249812, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:28<04:03, 18.98it/s, Loss=0.0249812, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:28<04:03, 18.98it/s, Loss=0.0269312, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:28<04:00, 19.19it/s, Loss=0.0269312, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:29<04:00, 19.19it/s, Loss=0.0199168, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:29<04:07, 18.66it/s, Loss=0.0199168, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:29<04:07, 18.66it/s, Loss=0.0260367, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:29<03:59, 19.22it/s, Loss=0.0260367, Depth Loss=0.0000000, Number Gaussians=246537]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [215,0,0], thread: [39,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [167,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [90,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [169,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [216,0,0], thread: [58,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [207,0,0], thread: [90,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [43,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [11,0,0], thread: [53,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   8%|▊         | 400/5000 [00:29<05:41, 13.47it/s, Loss=0.0260367, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "\n",
      "Generating GS for 429_60327_116727\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60327_116727\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0200993, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:24, 11.23it/s, Loss=0.0200993, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:24, 11.23it/s, Loss=0.0203545, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:01, 11.82it/s, Loss=0.0203545, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:01, 11.82it/s, Loss=0.0295435, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:42, 12.33it/s, Loss=0.0295435, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:42, 12.33it/s, Loss=0.0326551, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:07, 11.61it/s, Loss=0.0326551, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:07, 11.61it/s, Loss=0.0253355, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:56, 11.88it/s, Loss=0.0253355, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<06:56, 11.88it/s, Loss=0.0213108, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:55, 11.90it/s, Loss=0.0213108, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:55, 11.90it/s, Loss=0.0203580, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:48, 12.08it/s, Loss=0.0203580, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:48, 12.08it/s, Loss=0.0146989, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:37, 12.38it/s, Loss=0.0146989, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<06:37, 12.38it/s, Loss=0.0205366, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:47, 12.05it/s, Loss=0.0205366, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<06:47, 12.05it/s, Loss=0.0211855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:46, 12.06it/s, Loss=0.0211855, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<06:46, 12.06it/s, Loss=0.0152492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:37, 12.30it/s, Loss=0.0152492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:37, 12.30it/s, Loss=0.0303319, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:45, 12.03it/s, Loss=0.0303319, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<06:45, 12.03it/s, Loss=0.0221671, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:53, 11.79it/s, Loss=0.0221671, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<06:53, 11.79it/s, Loss=0.0195923, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:47, 11.93it/s, Loss=0.0195923, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<06:47, 11.93it/s, Loss=0.0128121, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:44, 12.00it/s, Loss=0.0128121, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<06:44, 12.00it/s, Loss=0.0155332, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:45, 11.94it/s, Loss=0.0155332, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<06:45, 11.94it/s, Loss=0.0182958, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:14<06:47, 11.85it/s, Loss=0.0182958, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<06:47, 11.85it/s, Loss=0.0202501, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:15<06:43, 11.96it/s, Loss=0.0202501, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:15<06:43, 11.96it/s, Loss=0.0157448, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:40, 12.00it/s, Loss=0.0157448, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:16<06:40, 12.00it/s, Loss=0.0179276, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:16<06:42, 11.94it/s, Loss=0.0179276, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:17<06:42, 11.94it/s, Loss=0.0232274, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:17<06:08, 13.00it/s, Loss=0.0232274, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:17<06:08, 13.00it/s, Loss=0.0134560, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:17<05:35, 14.27it/s, Loss=0.0134560, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:18<05:35, 14.27it/s, Loss=0.0167236, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:18<05:11, 15.33it/s, Loss=0.0167236, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:18<05:11, 15.33it/s, Loss=0.0281195, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:18<05:03, 15.68it/s, Loss=0.0281195, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:19<05:03, 15.68it/s, Loss=0.0193935, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:19<04:51, 16.27it/s, Loss=0.0193935, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:20<04:51, 16.27it/s, Loss=0.0256950, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:20<04:50, 16.32it/s, Loss=0.0256950, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:20<04:50, 16.32it/s, Loss=0.0242970, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:20<04:49, 16.34it/s, Loss=0.0242970, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:21<04:49, 16.34it/s, Loss=0.0162094, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:21<04:42, 16.69it/s, Loss=0.0162094, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:21<04:42, 16.69it/s, Loss=0.0172353, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:21<04:35, 17.07it/s, Loss=0.0172353, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:22<04:35, 17.07it/s, Loss=0.0193661, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:22<04:33, 17.16it/s, Loss=0.0193661, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:22<04:33, 17.16it/s, Loss=0.0146869, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:22<04:18, 18.15it/s, Loss=0.0146869, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:23<04:18, 18.15it/s, Loss=0.0187546, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:23<04:00, 19.49it/s, Loss=0.0187546, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:23<04:00, 19.49it/s, Loss=0.0187860, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:23<03:47, 20.50it/s, Loss=0.0187860, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:24<03:47, 20.50it/s, Loss=0.0258171, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:24<03:39, 21.18it/s, Loss=0.0258171, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:24<03:39, 21.18it/s, Loss=0.0183371, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:24<03:38, 21.29it/s, Loss=0.0183371, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:25<03:38, 21.29it/s, Loss=0.0211616, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:25<03:33, 21.78it/s, Loss=0.0211616, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:25<03:33, 21.78it/s, Loss=0.0182925, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:25<03:31, 21.87it/s, Loss=0.0182925, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:26<03:31, 21.87it/s, Loss=0.0173577, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:26<03:26, 22.34it/s, Loss=0.0173577, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:26<03:26, 22.34it/s, Loss=0.0124746, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:26<03:24, 22.55it/s, Loss=0.0124746, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:26<03:24, 22.55it/s, Loss=0.0159871, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:26<03:24, 22.46it/s, Loss=0.0159871, Depth Loss=0.0000000, Number Gaussians=246537]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [195,0,0], thread: [6,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [61,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [90,0,0], thread: [29,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [50,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [144,0,0], thread: [21,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [234,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   8%|▊         | 400/5000 [00:26<05:10, 14.83it/s, Loss=0.0159871, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "\n",
      "Generating GS for 429_60365_116961\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60365_116961\n",
      "Generating GS for 431_60932_118718\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60932_118718\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0326554, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   0%|          | 10/5000 [00:00<05:58, 13.93it/s, Loss=0.0326554, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   0%|          | 10/5000 [00:01<05:58, 13.93it/s, Loss=0.0364668, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   0%|          | 20/5000 [00:01<05:40, 14.61it/s, Loss=0.0364668, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   0%|          | 20/5000 [00:02<05:40, 14.61it/s, Loss=0.0301241, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 30/5000 [00:02<05:28, 15.12it/s, Loss=0.0301241, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 30/5000 [00:02<05:28, 15.12it/s, Loss=0.0405964, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 40/5000 [00:02<05:27, 15.13it/s, Loss=0.0405964, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 40/5000 [00:03<05:27, 15.13it/s, Loss=0.0344934, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 50/5000 [00:03<05:30, 14.97it/s, Loss=0.0344934, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 50/5000 [00:03<05:30, 14.97it/s, Loss=0.0356072, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 60/5000 [00:03<05:24, 15.22it/s, Loss=0.0356072, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|          | 60/5000 [00:04<05:24, 15.22it/s, Loss=0.0275919, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|▏         | 70/5000 [00:04<05:20, 15.40it/s, Loss=0.0275919, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<05:20, 15.40it/s, Loss=0.0384070, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<05:25, 15.13it/s, Loss=0.0384070, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<05:25, 15.13it/s, Loss=0.0242242, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 90/5000 [00:05<05:17, 15.48it/s, Loss=0.0242242, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<05:17, 15.48it/s, Loss=0.0258790, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 100/5000 [00:06<05:14, 15.59it/s, Loss=0.0258790, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<05:14, 15.59it/s, Loss=0.0196580, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 110/5000 [00:07<05:12, 15.63it/s, Loss=0.0196580, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 110/5000 [00:07<05:12, 15.63it/s, Loss=0.0328083, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 120/5000 [00:07<05:16, 15.42it/s, Loss=0.0328083, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   2%|▏         | 120/5000 [00:08<05:16, 15.42it/s, Loss=0.0310999, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 130/5000 [00:08<05:15, 15.46it/s, Loss=0.0310999, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<05:15, 15.46it/s, Loss=0.0297971, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 140/5000 [00:09<05:12, 15.57it/s, Loss=0.0297971, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 140/5000 [00:09<05:12, 15.57it/s, Loss=0.0214053, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 150/5000 [00:09<05:10, 15.60it/s, Loss=0.0214053, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 150/5000 [00:10<05:10, 15.60it/s, Loss=0.0214896, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 160/5000 [00:10<05:09, 15.62it/s, Loss=0.0214896, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 160/5000 [00:11<05:09, 15.62it/s, Loss=0.0263618, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 170/5000 [00:11<05:07, 15.68it/s, Loss=0.0263618, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   3%|▎         | 170/5000 [00:11<05:07, 15.68it/s, Loss=0.0213585, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▎         | 180/5000 [00:11<05:05, 15.77it/s, Loss=0.0213585, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▎         | 180/5000 [00:12<05:05, 15.77it/s, Loss=0.0332117, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▍         | 190/5000 [00:12<05:05, 15.75it/s, Loss=0.0332117, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▍         | 190/5000 [00:12<05:05, 15.75it/s, Loss=0.0268613, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▍         | 200/5000 [00:12<05:05, 15.70it/s, Loss=0.0268613, Depth Loss=0.0000000, Number Gaussians=486277]\n",
      "Training progress:   4%|▍         | 200/5000 [00:13<05:05, 15.70it/s, Loss=0.0283198, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   4%|▍         | 210/5000 [00:13<04:52, 16.37it/s, Loss=0.0283198, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   4%|▍         | 210/5000 [00:13<04:52, 16.37it/s, Loss=0.0287376, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   4%|▍         | 220/5000 [00:13<04:34, 17.38it/s, Loss=0.0287376, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   4%|▍         | 220/5000 [00:14<04:34, 17.38it/s, Loss=0.0290417, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▍         | 230/5000 [00:14<04:24, 18.05it/s, Loss=0.0290417, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▍         | 230/5000 [00:14<04:24, 18.05it/s, Loss=0.0216630, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▍         | 240/5000 [00:14<04:14, 18.71it/s, Loss=0.0216630, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▍         | 240/5000 [00:15<04:14, 18.71it/s, Loss=0.0218110, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 250/5000 [00:15<04:10, 18.98it/s, Loss=0.0218110, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 250/5000 [00:16<04:10, 18.98it/s, Loss=0.0269715, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 260/5000 [00:16<04:09, 18.98it/s, Loss=0.0269715, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 260/5000 [00:16<04:09, 18.98it/s, Loss=0.0247689, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 270/5000 [00:16<04:04, 19.34it/s, Loss=0.0247689, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   5%|▌         | 270/5000 [00:17<04:04, 19.34it/s, Loss=0.0258274, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   6%|▌         | 280/5000 [00:17<04:01, 19.53it/s, Loss=0.0258274, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   6%|▌         | 280/5000 [00:17<04:01, 19.53it/s, Loss=0.0286624, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   6%|▌         | 290/5000 [00:17<04:02, 19.45it/s, Loss=0.0286624, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   6%|▌         | 290/5000 [00:18<04:02, 19.45it/s, Loss=0.0250232, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "Training progress:   6%|▌         | 300/5000 [00:18<04:03, 19.30it/s, Loss=0.0250232, Depth Loss=0.0000000, Number Gaussians=244163]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [102,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [134,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [151,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [214,0,0], thread: [9,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [73,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [133,0,0], thread: [0,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [135,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [170,0,0], thread: [14,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [102,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [71,0,0], thread: [98,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [157,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [151,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [99,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [180,0,0], thread: [6,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [33,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [229,0,0], thread: [117,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [73,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [64,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [31,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [101,0,0], thread: [55,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [104,0,0], thread: [114,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [76,0,0], thread: [10,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [171,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [185,0,0], thread: [29,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [143,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [105,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [216,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [170,0,0], thread: [62,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [201,0,0], thread: [81,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [103,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [103,0,0], thread: [119,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [195,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [157,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [219,0,0], thread: [45,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [90,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [150,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [19,0,0], thread: [30,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [19,0,0], thread: [91,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [71,0,0], thread: [59,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [94,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [128,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [181,0,0], thread: [70,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [194,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [89,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [212,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [183,0,0], thread: [6,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [111,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [3,0,0], thread: [66,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [153,0,0], thread: [5,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [144,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [78,0,0], thread: [78,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [16,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [82,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [87,0,0], thread: [0,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [222,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [22,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [29,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [97,0,0], thread: [87,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [173,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [204,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [15,0,0], thread: [16,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [22,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [190,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [95,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [95,0,0], thread: [16,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [14,0,0], thread: [3,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [14,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [5,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [53,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [181,0,0], thread: [28,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [88,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [18,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [131,0,0], thread: [83,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [109,0,0], thread: [18,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [51,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [53,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [83,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [220,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [140,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [189,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [178,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [211,0,0], thread: [84,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [13,0,0], thread: [14,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [59,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [25,0,0], thread: [112,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [118,0,0], thread: [30,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [96,0,0], thread: [31,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [25,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [189,0,0], thread: [57,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [191,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [197,0,0], thread: [21,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [163,0,0], thread: [14,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [42,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [192,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [116,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [193,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [54,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [178,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [86,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [174,0,0], thread: [28,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [221,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [9,0,0], thread: [12,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [44,0,0], thread: [57,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [85,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [221,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [177,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [63,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:18<04:44, 16.54it/s, Loss=0.0250232, Depth Loss=0.0000000, Number Gaussians=244163]\n",
      "\n",
      "Generating GS for 431_60945_118758\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60945_118758\n",
      "Generating GS for 431_60963_118818\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60963_118818\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0427831, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:49, 12.19it/s, Loss=0.0427831, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:49, 12.19it/s, Loss=0.0401857, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:21, 13.06it/s, Loss=0.0401857, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:21, 13.06it/s, Loss=0.0400740, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:12, 13.35it/s, Loss=0.0400740, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:12, 13.35it/s, Loss=0.0786774, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:07, 13.51it/s, Loss=0.0786774, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:07, 13.51it/s, Loss=0.0342340, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:05, 13.54it/s, Loss=0.0342340, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:05, 13.54it/s, Loss=0.0251749, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 60/5000 [00:04<05:59, 13.74it/s, Loss=0.0251749, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|          | 60/5000 [00:05<05:59, 13.74it/s, Loss=0.0325768, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<05:56, 13.82it/s, Loss=0.0325768, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<05:56, 13.82it/s, Loss=0.0219765, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<05:52, 13.94it/s, Loss=0.0219765, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<05:52, 13.94it/s, Loss=0.0523263, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<05:52, 13.94it/s, Loss=0.0523263, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<05:52, 13.94it/s, Loss=0.0240407, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<05:52, 13.91it/s, Loss=0.0240407, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<05:52, 13.91it/s, Loss=0.0268882, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<05:52, 13.88it/s, Loss=0.0268882, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<05:52, 13.88it/s, Loss=0.0224596, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 120/5000 [00:08<05:53, 13.80it/s, Loss=0.0224596, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<05:53, 13.80it/s, Loss=0.0176557, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<05:51, 13.86it/s, Loss=0.0176557, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<05:51, 13.86it/s, Loss=0.0202952, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<05:47, 13.98it/s, Loss=0.0202952, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<05:47, 13.98it/s, Loss=0.0200192, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 150/5000 [00:10<05:47, 13.97it/s, Loss=0.0200192, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<05:47, 13.97it/s, Loss=0.0193216, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 160/5000 [00:11<05:46, 13.96it/s, Loss=0.0193216, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<05:46, 13.96it/s, Loss=0.0226873, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 170/5000 [00:12<05:45, 13.99it/s, Loss=0.0226873, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<05:45, 13.99it/s, Loss=0.0172884, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<05:48, 13.83it/s, Loss=0.0172884, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<05:48, 13.83it/s, Loss=0.0294713, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▍         | 190/5000 [00:13<05:50, 13.72it/s, Loss=0.0294713, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<05:50, 13.72it/s, Loss=0.0137265, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▍         | 200/5000 [00:14<05:45, 13.87it/s, Loss=0.0137265, Depth Loss=0.0000000, Number Gaussians=964114]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:45, 13.87it/s, Loss=0.0183872, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:18, 15.05it/s, Loss=0.0183872, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:18, 15.05it/s, Loss=0.0185663, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   4%|▍         | 220/5000 [00:15<04:54, 16.25it/s, Loss=0.0185663, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<04:54, 16.25it/s, Loss=0.0131030, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:37, 17.19it/s, Loss=0.0131030, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:37, 17.19it/s, Loss=0.0266234, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▍         | 240/5000 [00:16<04:26, 17.88it/s, Loss=0.0266234, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:26, 17.88it/s, Loss=0.0534097, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:19, 18.28it/s, Loss=0.0534097, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:19, 18.28it/s, Loss=0.0325818, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 260/5000 [00:17<04:12, 18.79it/s, Loss=0.0325818, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:12, 18.79it/s, Loss=0.0188490, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:07, 19.12it/s, Loss=0.0188490, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:07, 19.12it/s, Loss=0.0171613, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   6%|▌         | 280/5000 [00:18<04:04, 19.31it/s, Loss=0.0171613, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:04, 19.31it/s, Loss=0.0132607, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:00, 19.58it/s, Loss=0.0132607, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:00, 19.58it/s, Loss=0.0399409, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "Training progress:   6%|▌         | 300/5000 [00:19<03:58, 19.74it/s, Loss=0.0399409, Depth Loss=0.0000000, Number Gaussians=483081]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [176,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [134,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:19<05:07, 15.27it/s, Loss=0.0399409, Depth Loss=0.0000000, Number Gaussians=483081]\n",
      "\n",
      "Generating GS for 429_60360_116956\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60360_116956\n",
      "Generating GS for 433_61497_120187\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61497_120187\n",
      "Generating GS for 431_60889_118394\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60889_118394\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0371996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:44, 12.35it/s, Loss=0.0371996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:44, 12.35it/s, Loss=0.0332311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:28, 12.81it/s, Loss=0.0332311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:28, 12.81it/s, Loss=0.0313990, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:20, 13.07it/s, Loss=0.0313990, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:20, 13.07it/s, Loss=0.0550498, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:20, 13.03it/s, Loss=0.0550498, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:20, 13.03it/s, Loss=0.0297726, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:19, 13.04it/s, Loss=0.0297726, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:19, 13.04it/s, Loss=0.0333851, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:19, 13.01it/s, Loss=0.0333851, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:19, 13.01it/s, Loss=0.0313425, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:19, 12.99it/s, Loss=0.0313425, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:19, 12.99it/s, Loss=0.0278745, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:20, 12.95it/s, Loss=0.0278745, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:20, 12.95it/s, Loss=0.0359234, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<06:18, 12.98it/s, Loss=0.0359234, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:18, 12.98it/s, Loss=0.0263495, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<06:18, 12.94it/s, Loss=0.0263495, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:18, 12.94it/s, Loss=0.0287462, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:18, 12.93it/s, Loss=0.0287462, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:18, 12.93it/s, Loss=0.0256262, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:18, 12.89it/s, Loss=0.0256262, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<06:18, 12.89it/s, Loss=0.0232161, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:17, 12.89it/s, Loss=0.0232161, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:17, 12.89it/s, Loss=0.0315522, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<06:16, 12.90it/s, Loss=0.0315522, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:16, 12.90it/s, Loss=0.0248531, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:16, 12.89it/s, Loss=0.0248531, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:16, 12.89it/s, Loss=0.0336833, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:17, 12.83it/s, Loss=0.0336833, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:17, 12.83it/s, Loss=0.0423163, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:17, 12.79it/s, Loss=0.0423163, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:17, 12.79it/s, Loss=0.0293930, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<06:19, 12.70it/s, Loss=0.0293930, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<06:19, 12.70it/s, Loss=0.0258567, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<06:18, 12.72it/s, Loss=0.0258567, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:18, 12.72it/s, Loss=0.0402042, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<06:16, 12.77it/s, Loss=0.0402042, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:16<06:16, 12.77it/s, Loss=0.0259276, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:16<05:41, 14.01it/s, Loss=0.0259276, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:16<05:41, 14.01it/s, Loss=0.0405410, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<05:14, 15.20it/s, Loss=0.0405410, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:17<05:14, 15.20it/s, Loss=0.0221599, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:17<04:54, 16.22it/s, Loss=0.0221599, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:17<04:54, 16.22it/s, Loss=0.0497480, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:40, 16.99it/s, Loss=0.0497480, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:18<04:40, 16.99it/s, Loss=0.0297117, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:32, 17.45it/s, Loss=0.0297117, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:32, 17.45it/s, Loss=0.0224779, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:25, 17.85it/s, Loss=0.0224779, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:19<04:25, 17.85it/s, Loss=0.0280849, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:20, 18.18it/s, Loss=0.0280849, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:20, 18.18it/s, Loss=0.0372198, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:17, 18.35it/s, Loss=0.0372198, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:20<04:17, 18.35it/s, Loss=0.0226356, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:14, 18.52it/s, Loss=0.0226356, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:14, 18.52it/s, Loss=0.0223947, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<04:12, 18.58it/s, Loss=0.0223947, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:21<04:12, 18.58it/s, Loss=0.0348352, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:21<03:57, 19.74it/s, Loss=0.0348352, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:21<03:57, 19.74it/s, Loss=0.0325447, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:21<03:43, 20.93it/s, Loss=0.0325447, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:22<03:43, 20.93it/s, Loss=0.0313500, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:22<03:36, 21.55it/s, Loss=0.0313500, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:22<03:36, 21.55it/s, Loss=0.0358783, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:22<03:30, 22.09it/s, Loss=0.0358783, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:22<03:30, 22.09it/s, Loss=0.0332795, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:22<03:25, 22.66it/s, Loss=0.0332795, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:23<03:25, 22.66it/s, Loss=0.0281850, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:23<03:21, 22.99it/s, Loss=0.0281850, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:23<03:21, 22.99it/s, Loss=0.0208274, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:23<03:20, 23.13it/s, Loss=0.0208274, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:24<03:20, 23.13it/s, Loss=0.0422496, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:24<03:17, 23.34it/s, Loss=0.0422496, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:24<03:17, 23.34it/s, Loss=0.0186061, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:24<03:14, 23.72it/s, Loss=0.0186061, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:25<03:14, 23.72it/s, Loss=0.0593293, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:25<03:12, 23.86it/s, Loss=0.0593293, Depth Loss=0.0000000, Number Gaussians=246537]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [199,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [99,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   8%|▊         | 400/5000 [00:25<04:48, 15.92it/s, Loss=0.0593293, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "\n",
      "Generating GS for 429_60355_117003\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60355_117003\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0790351, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:56, 11.99it/s, Loss=0.0790351, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:56, 11.99it/s, Loss=0.0683017, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:36, 12.56it/s, Loss=0.0683017, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:36, 12.56it/s, Loss=0.0680924, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:46, 12.24it/s, Loss=0.0680924, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:46, 12.24it/s, Loss=0.0524165, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:28, 12.76it/s, Loss=0.0524165, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:28, 12.76it/s, Loss=0.0546506, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:22, 12.94it/s, Loss=0.0546506, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:22, 12.94it/s, Loss=0.0420225, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:19, 13.02it/s, Loss=0.0420225, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:19, 13.02it/s, Loss=0.0603801, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:26, 12.77it/s, Loss=0.0603801, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:26, 12.77it/s, Loss=0.0383200, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:20, 12.94it/s, Loss=0.0383200, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:20, 12.94it/s, Loss=0.0442427, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<06:14, 13.11it/s, Loss=0.0442427, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:14, 13.11it/s, Loss=0.0529452, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<06:12, 13.15it/s, Loss=0.0529452, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:12, 13.15it/s, Loss=0.0456067, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:15, 13.02it/s, Loss=0.0456067, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:15, 13.02it/s, Loss=0.0381942, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:08, 13.23it/s, Loss=0.0381942, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:08, 13.23it/s, Loss=0.0364939, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<06:00, 13.51it/s, Loss=0.0364939, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:00, 13.51it/s, Loss=0.0447155, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<06:00, 13.47it/s, Loss=0.0447155, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:00, 13.47it/s, Loss=0.0408237, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:04, 13.29it/s, Loss=0.0408237, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:04, 13.29it/s, Loss=0.0449417, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:06, 13.22it/s, Loss=0.0449417, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:06, 13.22it/s, Loss=0.0583427, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:04, 13.26it/s, Loss=0.0583427, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:04, 13.26it/s, Loss=0.0513733, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<06:05, 13.17it/s, Loss=0.0513733, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<06:05, 13.17it/s, Loss=0.0409734, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<06:00, 13.33it/s, Loss=0.0409734, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:00, 13.33it/s, Loss=0.0342311, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:56, 13.45it/s, Loss=0.0342311, Depth Loss=0.0000000, Number Gaussians=717966]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [416,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<06:07, 13.05it/s, Loss=0.0342311, Depth Loss=0.0000000, Number Gaussians=717966]\n",
      "\n",
      "Generating GS for 429_60388_117059\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60388_117059\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:01<?, ?it/s, Loss=0.0404194, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<08:54,  9.34it/s, Loss=0.0404194, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:02<08:54,  9.34it/s, Loss=0.0350071, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<08:37,  9.62it/s, Loss=0.0350071, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:03<08:37,  9.62it/s, Loss=0.0339821, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<08:31,  9.71it/s, Loss=0.0339821, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:04<08:31,  9.71it/s, Loss=0.0350424, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<08:28,  9.75it/s, Loss=0.0350424, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:05<08:28,  9.75it/s, Loss=0.0319760, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<08:34,  9.61it/s, Loss=0.0319760, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:06<08:34,  9.61it/s, Loss=0.0278382, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<08:31,  9.66it/s, Loss=0.0278382, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:07<08:31,  9.66it/s, Loss=0.0196309, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:07<08:27,  9.71it/s, Loss=0.0196309, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:08<08:27,  9.71it/s, Loss=0.0252211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:08<08:19,  9.84it/s, Loss=0.0252211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:09<08:19,  9.84it/s, Loss=0.0265817, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:09<08:25,  9.72it/s, Loss=0.0265817, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:10<08:25,  9.72it/s, Loss=0.0240697, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:10<08:28,  9.64it/s, Loss=0.0240697, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:11<08:28,  9.64it/s, Loss=0.0213447, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:11<08:26,  9.66it/s, Loss=0.0213447, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:12<08:26,  9.66it/s, Loss=0.0218569, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:12<08:21,  9.73it/s, Loss=0.0218569, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:13<08:21,  9.73it/s, Loss=0.0217275, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:13<08:23,  9.68it/s, Loss=0.0217275, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:14<08:23,  9.68it/s, Loss=0.0188974, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:14<08:18,  9.76it/s, Loss=0.0188974, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:15<08:18,  9.76it/s, Loss=0.0204701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:15<08:20,  9.70it/s, Loss=0.0204701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:16<08:20,  9.70it/s, Loss=0.0206864, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:16<08:13,  9.80it/s, Loss=0.0206864, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:17<08:13,  9.80it/s, Loss=0.0186785, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:17<08:10,  9.86it/s, Loss=0.0186785, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:18<08:10,  9.86it/s, Loss=0.0201902, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:18<08:10,  9.82it/s, Loss=0.0201902, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:19<08:10,  9.82it/s, Loss=0.0226478, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:19<08:11,  9.78it/s, Loss=0.0226478, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:20<08:11,  9.78it/s, Loss=0.0199537, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:20<08:08,  9.83it/s, Loss=0.0199537, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:21<08:08,  9.83it/s, Loss=0.0214191, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:21<07:25, 10.74it/s, Loss=0.0214191, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:21<07:25, 10.74it/s, Loss=0.0211456, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:21<06:55, 11.50it/s, Loss=0.0211456, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:22<06:55, 11.50it/s, Loss=0.0182842, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:22<06:35, 12.07it/s, Loss=0.0182842, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:23<06:35, 12.07it/s, Loss=0.0189060, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:23<06:19, 12.55it/s, Loss=0.0189060, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:24<06:19, 12.55it/s, Loss=0.0192632, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:24<06:06, 12.96it/s, Loss=0.0192632, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:24<06:06, 12.96it/s, Loss=0.0185504, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:24<05:57, 13.24it/s, Loss=0.0185504, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:25<05:57, 13.24it/s, Loss=0.0197564, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:25<05:51, 13.47it/s, Loss=0.0197564, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:26<05:51, 13.47it/s, Loss=0.0214211, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:26<05:47, 13.59it/s, Loss=0.0214211, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:27<05:47, 13.59it/s, Loss=0.0179985, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:27<05:45, 13.65it/s, Loss=0.0179985, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:27<05:45, 13.65it/s, Loss=0.0221260, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:27<05:41, 13.75it/s, Loss=0.0221260, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:28<05:41, 13.75it/s, Loss=0.0204378, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:28<05:23, 14.52it/s, Loss=0.0204378, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:28<05:23, 14.52it/s, Loss=0.0190332, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:28<05:06, 15.28it/s, Loss=0.0190332, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:29<05:06, 15.28it/s, Loss=0.0174833, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:29<04:54, 15.85it/s, Loss=0.0174833, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:30<04:54, 15.85it/s, Loss=0.0173055, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:30<04:46, 16.29it/s, Loss=0.0173055, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:30<04:46, 16.29it/s, Loss=0.0170844, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:30<04:41, 16.49it/s, Loss=0.0170844, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:31<04:41, 16.49it/s, Loss=0.0191202, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:31<04:37, 16.74it/s, Loss=0.0191202, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:31<04:37, 16.74it/s, Loss=0.0211793, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:31<04:32, 16.99it/s, Loss=0.0211793, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:32<04:32, 16.99it/s, Loss=0.0174594, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:32<04:29, 17.14it/s, Loss=0.0174594, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:32<04:29, 17.14it/s, Loss=0.0161770, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:32<04:27, 17.22it/s, Loss=0.0161770, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:33<04:27, 17.22it/s, Loss=0.0164355, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:33<04:26, 17.26it/s, Loss=0.0164355, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:34<04:26, 17.26it/s, Loss=0.0148015, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:34<04:14, 18.06it/s, Loss=0.0148015, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:34<04:14, 18.06it/s, Loss=0.0184732, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:34<04:05, 18.62it/s, Loss=0.0184732, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:34<04:05, 18.62it/s, Loss=0.0176694, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:34<03:56, 19.30it/s, Loss=0.0176694, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:35<03:56, 19.30it/s, Loss=0.0205907, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:35<03:51, 19.68it/s, Loss=0.0205907, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:35<03:51, 19.68it/s, Loss=0.0180812, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:35<03:48, 19.89it/s, Loss=0.0180812, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:36<03:48, 19.89it/s, Loss=0.0205623, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:36<03:47, 19.91it/s, Loss=0.0205623, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:36<03:47, 19.91it/s, Loss=0.0170849, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:36<03:45, 20.13it/s, Loss=0.0170849, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:37<03:45, 20.13it/s, Loss=0.0197615, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:37<03:44, 20.13it/s, Loss=0.0197615, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:37<03:44, 20.13it/s, Loss=0.0172641, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:37<03:42, 20.24it/s, Loss=0.0172641, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:38<03:42, 20.24it/s, Loss=0.0166667, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|█         | 500/5000 [00:38<03:41, 20.35it/s, Loss=0.0166667, Depth Loss=0.0000000, Number Gaussians=124293]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [109,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [9,0,0], thread: [68,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [59,0,0], thread: [104,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [24,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [23,0,0], thread: [42,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [7,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [64,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [65,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [40,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [86,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [62,0,0], thread: [36,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [47,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [87,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [18,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [63,0,0], thread: [29,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [15,0,0], thread: [93,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [6,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [17,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [118,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [61,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [20,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:  10%|█         | 500/5000 [00:38<05:46, 12.99it/s, Loss=0.0166667, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "\n",
      "Generating GS for 433_61509_120201\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61509_120201\n",
      "Generating GS for 431_60893_118398\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60893_118398\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0634267, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:39, 10.86it/s, Loss=0.0634267, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:39, 10.86it/s, Loss=0.0572745, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:22, 11.26it/s, Loss=0.0572745, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:22, 11.26it/s, Loss=0.0597278, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:13, 11.46it/s, Loss=0.0597278, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:13, 11.46it/s, Loss=0.0547464, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:09, 11.55it/s, Loss=0.0547464, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:09, 11.55it/s, Loss=0.0679121, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<07:09, 11.53it/s, Loss=0.0679121, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<07:09, 11.53it/s, Loss=0.0450921, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<07:07, 11.57it/s, Loss=0.0450921, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<07:07, 11.57it/s, Loss=0.0533528, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:03, 11.64it/s, Loss=0.0533528, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:03, 11.64it/s, Loss=0.0512388, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<07:00, 11.70it/s, Loss=0.0512388, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<07:00, 11.70it/s, Loss=0.0544952, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<07:01, 11.65it/s, Loss=0.0544952, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<07:01, 11.65it/s, Loss=0.0682210, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<07:03, 11.57it/s, Loss=0.0682210, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:03, 11.57it/s, Loss=0.0556462, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<07:03, 11.54it/s, Loss=0.0556462, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<07:03, 11.54it/s, Loss=0.0458468, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<07:00, 11.60it/s, Loss=0.0458468, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:00, 11.60it/s, Loss=0.0537995, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<07:00, 11.57it/s, Loss=0.0537995, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:00, 11.57it/s, Loss=0.0423095, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<06:58, 11.60it/s, Loss=0.0423095, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<06:58, 11.60it/s, Loss=0.0468101, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:56, 11.63it/s, Loss=0.0468101, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<06:56, 11.63it/s, Loss=0.0606817, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:54, 11.67it/s, Loss=0.0606817, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<06:54, 11.67it/s, Loss=0.0629996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:14<06:53, 11.68it/s, Loss=0.0629996, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<06:53, 11.68it/s, Loss=0.0649450, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:15<06:55, 11.61it/s, Loss=0.0649450, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<06:55, 11.61it/s, Loss=0.0462374, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:16<06:55, 11.57it/s, Loss=0.0462374, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:17<06:55, 11.57it/s, Loss=0.0361496, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:17<06:51, 11.67it/s, Loss=0.0361496, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:17<06:51, 11.67it/s, Loss=0.0470105, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:17<06:12, 12.85it/s, Loss=0.0470105, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:18<06:12, 12.85it/s, Loss=0.0510603, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:18<05:45, 13.82it/s, Loss=0.0510603, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:19<05:45, 13.82it/s, Loss=0.0429108, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:19<05:32, 14.36it/s, Loss=0.0429108, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:19<05:32, 14.36it/s, Loss=0.0366767, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:19<05:35, 14.18it/s, Loss=0.0366767, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:20<05:35, 14.18it/s, Loss=0.0696722, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:20<05:18, 14.92it/s, Loss=0.0696722, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:20<05:18, 14.92it/s, Loss=0.0383319, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:20<05:04, 15.59it/s, Loss=0.0383319, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:21<05:04, 15.59it/s, Loss=0.0469355, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:21<04:57, 15.90it/s, Loss=0.0469355, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:22<04:57, 15.90it/s, Loss=0.0468507, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:22<04:52, 16.13it/s, Loss=0.0468507, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:22<04:52, 16.13it/s, Loss=0.0403213, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:22<04:52, 16.13it/s, Loss=0.0403213, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:23<04:52, 16.13it/s, Loss=0.0443943, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:23<04:47, 16.37it/s, Loss=0.0443943, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [88,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [31,0,0], thread: [28,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [233,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [188,0,0], thread: [120,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:23<06:07, 12.79it/s, Loss=0.0443943, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 433_61517_120210\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61517_120210\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0214229, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:25, 12.95it/s, Loss=0.0214229, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:25, 12.95it/s, Loss=0.0174301, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:07, 13.54it/s, Loss=0.0174301, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:07, 13.54it/s, Loss=0.0184683, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:05, 13.60it/s, Loss=0.0184683, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:05, 13.60it/s, Loss=0.0171166, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:14, 13.23it/s, Loss=0.0171166, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:14, 13.23it/s, Loss=0.0182782, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:08, 13.45it/s, Loss=0.0182782, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:08, 13.45it/s, Loss=0.0152683, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:02, 13.63it/s, Loss=0.0152683, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:02, 13.63it/s, Loss=0.0149356, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<05:59, 13.72it/s, Loss=0.0149356, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<05:59, 13.72it/s, Loss=0.0127490, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<05:56, 13.80it/s, Loss=0.0127490, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<05:56, 13.80it/s, Loss=0.0145344, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<05:53, 13.88it/s, Loss=0.0145344, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<05:53, 13.88it/s, Loss=0.0131772, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<05:55, 13.77it/s, Loss=0.0131772, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<05:55, 13.77it/s, Loss=0.0144843, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<05:56, 13.71it/s, Loss=0.0144843, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<05:56, 13.71it/s, Loss=0.0142247, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:08<05:54, 13.75it/s, Loss=0.0142247, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<05:54, 13.75it/s, Loss=0.0110618, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<05:51, 13.84it/s, Loss=0.0110618, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<05:51, 13.84it/s, Loss=0.0115089, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<05:50, 13.86it/s, Loss=0.0115089, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<05:50, 13.86it/s, Loss=0.0146648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:10<05:49, 13.87it/s, Loss=0.0146648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<05:49, 13.87it/s, Loss=0.0126967, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:11<05:51, 13.79it/s, Loss=0.0126967, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<05:51, 13.79it/s, Loss=0.0124471, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:12<05:49, 13.82it/s, Loss=0.0124471, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<05:49, 13.82it/s, Loss=0.0128675, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<05:47, 13.86it/s, Loss=0.0128675, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<05:47, 13.86it/s, Loss=0.0175601, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:13<05:46, 13.90it/s, Loss=0.0175601, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<05:46, 13.90it/s, Loss=0.0122548, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:14<05:43, 13.95it/s, Loss=0.0122548, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:43, 13.95it/s, Loss=0.0151202, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:12, 15.33it/s, Loss=0.0151202, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:12, 15.33it/s, Loss=0.0121919, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:15<04:53, 16.28it/s, Loss=0.0121919, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<04:53, 16.28it/s, Loss=0.0128771, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<05:10, 15.37it/s, Loss=0.0128771, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<05:10, 15.37it/s, Loss=0.0116643, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:16<04:49, 16.45it/s, Loss=0.0116643, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:49, 16.45it/s, Loss=0.0119338, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:33, 17.36it/s, Loss=0.0119338, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:33, 17.36it/s, Loss=0.0117919, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:17<04:27, 17.72it/s, Loss=0.0117919, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:27, 17.72it/s, Loss=0.0113765, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:18, 18.33it/s, Loss=0.0113765, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:18, 18.33it/s, Loss=0.0173624, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:18<04:13, 18.59it/s, Loss=0.0173624, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:13, 18.59it/s, Loss=0.0148301, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:09, 18.88it/s, Loss=0.0148301, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:09, 18.88it/s, Loss=0.0108672, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:19<04:02, 19.38it/s, Loss=0.0108672, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [456,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:19<05:12, 15.04it/s, Loss=0.0108672, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 433_61532_120301\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61532_120301\n",
      "Generating GS for 429_60515_117738\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60515_117738\n",
      "Missing colmap data: 433_61366_119705\n",
      "Generating GS for 429_60354_116944\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60354_116944\n",
      "Generating GS for 433_61514_120207\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61514_120207\n",
      "Generating GS for 433_61535_120304\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61535_120304\n",
      "Generating GS for 431_60892_118397\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60892_118397\n",
      "Generating GS for 433_61523_120300\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61523_120300\n",
      "Generating GS for 429_60395_117232\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60395_117232\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0506228, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:51, 10.58it/s, Loss=0.0506228, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:51, 10.58it/s, Loss=0.0521261, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:42, 10.76it/s, Loss=0.0521261, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:42, 10.76it/s, Loss=0.0428962, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:31, 11.00it/s, Loss=0.0428962, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:31, 11.00it/s, Loss=0.0455349, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:30, 11.01it/s, Loss=0.0455349, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:30, 11.01it/s, Loss=0.0361118, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<07:32, 10.95it/s, Loss=0.0361118, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<07:32, 10.95it/s, Loss=0.0407892, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<07:34, 10.88it/s, Loss=0.0407892, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<07:34, 10.88it/s, Loss=0.0321376, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:31, 10.93it/s, Loss=0.0321376, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:07<07:31, 10.93it/s, Loss=0.0358241, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<07:30, 10.92it/s, Loss=0.0358241, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:08<07:30, 10.92it/s, Loss=0.0351836, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<07:35, 10.78it/s, Loss=0.0351836, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:09<07:35, 10.78it/s, Loss=0.0394202, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:39, 10.66it/s, Loss=0.0394202, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:10<07:39, 10.66it/s, Loss=0.0323780, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<07:40, 10.63it/s, Loss=0.0323780, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:11<07:40, 10.63it/s, Loss=0.0366694, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:41, 10.56it/s, Loss=0.0366694, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:12<07:41, 10.56it/s, Loss=0.0421864, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:47, 10.42it/s, Loss=0.0421864, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:13<07:47, 10.42it/s, Loss=0.0368854, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:13<07:45, 10.44it/s, Loss=0.0368854, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:14<07:45, 10.44it/s, Loss=0.0305002, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:14<07:43, 10.47it/s, Loss=0.0305002, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:14<07:43, 10.47it/s, Loss=0.0341644, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<07:38, 10.56it/s, Loss=0.0341644, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:15<07:38, 10.56it/s, Loss=0.0307886, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<07:36, 10.58it/s, Loss=0.0307886, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:16<07:36, 10.58it/s, Loss=0.0339052, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<07:37, 10.53it/s, Loss=0.0339052, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:17<07:37, 10.53it/s, Loss=0.0311983, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:17<07:38, 10.49it/s, Loss=0.0311983, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:18<07:38, 10.49it/s, Loss=0.0312701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:18<07:33, 10.58it/s, Loss=0.0312701, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:19<07:33, 10.58it/s, Loss=0.0359428, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:50, 11.66it/s, Loss=0.0359428, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:20<06:50, 11.66it/s, Loss=0.0332083, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:20<06:19, 12.59it/s, Loss=0.0332083, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:20<06:19, 12.59it/s, Loss=0.0346682, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:56, 13.38it/s, Loss=0.0346682, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:21<05:56, 13.38it/s, Loss=0.0342747, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:21<05:42, 13.90it/s, Loss=0.0342747, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:22<05:42, 13.90it/s, Loss=0.0343866, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:22<05:34, 14.22it/s, Loss=0.0343866, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:22<05:34, 14.22it/s, Loss=0.0311909, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:22<05:27, 14.49it/s, Loss=0.0311909, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:23<05:27, 14.49it/s, Loss=0.0302023, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:19, 14.80it/s, Loss=0.0302023, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:19, 14.80it/s, Loss=0.0295708, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:23<05:16, 14.90it/s, Loss=0.0295708, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:24<05:16, 14.90it/s, Loss=0.0302540, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:14, 14.99it/s, Loss=0.0302540, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:25<05:14, 14.99it/s, Loss=0.0327089, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:25<05:13, 14.97it/s, Loss=0.0327089, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:25<05:13, 14.97it/s, Loss=0.0346399, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:25<04:52, 16.05it/s, Loss=0.0346399, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:26<04:52, 16.05it/s, Loss=0.0376924, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:26<04:34, 17.03it/s, Loss=0.0376924, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:26<04:34, 17.03it/s, Loss=0.0361261, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:26<04:21, 17.86it/s, Loss=0.0361261, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:27<04:21, 17.86it/s, Loss=0.0315997, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:27<04:13, 18.36it/s, Loss=0.0315997, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:27<04:13, 18.36it/s, Loss=0.0289041, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:27<04:10, 18.53it/s, Loss=0.0289041, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:28<04:10, 18.53it/s, Loss=0.0302274, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:28<04:04, 19.00it/s, Loss=0.0302274, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:28<04:04, 19.00it/s, Loss=0.0315447, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:28<04:01, 19.16it/s, Loss=0.0315447, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:29<04:01, 19.16it/s, Loss=0.0323699, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:29<03:58, 19.34it/s, Loss=0.0323699, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:29<03:58, 19.34it/s, Loss=0.0334584, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:29<03:54, 19.65it/s, Loss=0.0334584, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:30<03:54, 19.65it/s, Loss=0.0275817, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:30<03:54, 19.61it/s, Loss=0.0275817, Depth Loss=0.0000000, Number Gaussians=246537]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [101,0,0], thread: [16,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [92,0,0], thread: [26,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [191,0,0], thread: [102,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [47,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   8%|▊         | 400/5000 [00:30<05:50, 13.13it/s, Loss=0.0275817, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "\n",
      "Generating GS for 431_60943_118736\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60943_118736\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0408653, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<05:25, 15.31it/s, Loss=0.0408653, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<05:25, 15.31it/s, Loss=0.0316001, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<05:09, 16.11it/s, Loss=0.0316001, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<05:09, 16.11it/s, Loss=0.0346150, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:01<05:03, 16.37it/s, Loss=0.0346150, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<05:03, 16.37it/s, Loss=0.0311286, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:02<05:00, 16.50it/s, Loss=0.0311286, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<05:00, 16.50it/s, Loss=0.0342951, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<04:58, 16.58it/s, Loss=0.0342951, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<04:58, 16.58it/s, Loss=0.0288581, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:03<04:53, 16.81it/s, Loss=0.0288581, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<04:53, 16.81it/s, Loss=0.0287906, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:04<04:55, 16.71it/s, Loss=0.0287906, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:04<04:55, 16.71it/s, Loss=0.0241722, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:04<04:53, 16.75it/s, Loss=0.0241722, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:05<04:53, 16.75it/s, Loss=0.0250688, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:05<04:51, 16.87it/s, Loss=0.0250688, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:05<04:51, 16.87it/s, Loss=0.0247754, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:05<04:49, 16.92it/s, Loss=0.0247754, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:06<04:49, 16.92it/s, Loss=0.0240947, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:06<04:50, 16.86it/s, Loss=0.0240947, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:07<04:50, 16.86it/s, Loss=0.0240415, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:07<04:49, 16.84it/s, Loss=0.0240415, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:07<04:49, 16.84it/s, Loss=0.0226513, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:07<04:49, 16.84it/s, Loss=0.0226513, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:08<04:49, 16.84it/s, Loss=0.0219636, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:08<04:48, 16.86it/s, Loss=0.0219636, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:08<04:48, 16.86it/s, Loss=0.0210229, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:08<04:46, 16.91it/s, Loss=0.0210229, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:09<04:46, 16.91it/s, Loss=0.0213980, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:09<04:45, 16.96it/s, Loss=0.0213980, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:10<04:45, 16.96it/s, Loss=0.0222304, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:10<04:43, 17.01it/s, Loss=0.0222304, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:10<04:43, 17.01it/s, Loss=0.0226222, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:10<04:42, 17.07it/s, Loss=0.0226222, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:11<04:42, 17.07it/s, Loss=0.0229705, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:11<04:43, 16.98it/s, Loss=0.0229705, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:11<04:43, 16.98it/s, Loss=0.0219176, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:11<04:42, 17.02it/s, Loss=0.0219176, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:12<04:42, 17.02it/s, Loss=0.0244409, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:12<04:10, 19.14it/s, Loss=0.0244409, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:12<04:10, 19.14it/s, Loss=0.0219183, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:12<03:44, 21.27it/s, Loss=0.0219183, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:12<03:44, 21.27it/s, Loss=0.0220946, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:12<03:27, 22.97it/s, Loss=0.0220946, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:13<03:27, 22.97it/s, Loss=0.0216970, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:13<03:15, 24.32it/s, Loss=0.0216970, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:13<03:15, 24.32it/s, Loss=0.0195724, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:13<03:07, 25.35it/s, Loss=0.0195724, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:14<03:07, 25.35it/s, Loss=0.0199343, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:14<03:00, 26.19it/s, Loss=0.0199343, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:14<03:00, 26.19it/s, Loss=0.0206316, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:14<02:56, 26.77it/s, Loss=0.0206316, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:14<02:56, 26.77it/s, Loss=0.0223325, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:14<02:53, 27.23it/s, Loss=0.0223325, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:15<02:53, 27.23it/s, Loss=0.0219225, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:15<02:51, 27.48it/s, Loss=0.0219225, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:15<02:51, 27.48it/s, Loss=0.0256243, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:15<02:50, 27.56it/s, Loss=0.0256243, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [316,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:15<04:03, 19.32it/s, Loss=0.0256243, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 427_59989_115990\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/427_59989_115990\n",
      "Generating GS for 429_60367_116963\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60367_116963\n",
      "Generating GS for 429_60420_117369\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60420_117369\n",
      "Generating GS for 433_61378_119876\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61378_119876\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:01<?, ?it/s, Loss=0.0470726, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<08:32,  9.73it/s, Loss=0.0470726, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<08:32,  9.73it/s, Loss=0.0420331, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:58, 10.40it/s, Loss=0.0420331, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:58, 10.40it/s, Loss=0.0415211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:43, 10.72it/s, Loss=0.0415211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:43, 10.72it/s, Loss=0.0399022, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:38, 10.81it/s, Loss=0.0399022, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:38, 10.81it/s, Loss=0.0390982, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<07:36, 10.83it/s, Loss=0.0390982, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<07:36, 10.83it/s, Loss=0.0374932, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<07:42, 10.67it/s, Loss=0.0374932, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<07:42, 10.67it/s, Loss=0.0358260, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:40, 10.72it/s, Loss=0.0358260, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:07<07:40, 10.72it/s, Loss=0.0333278, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<07:33, 10.84it/s, Loss=0.0333278, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:08<07:33, 10.84it/s, Loss=0.0326188, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<07:27, 10.98it/s, Loss=0.0326188, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:09<07:27, 10.98it/s, Loss=0.0322720, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:26, 10.98it/s, Loss=0.0322720, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:10<07:26, 10.98it/s, Loss=0.0293708, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<07:26, 10.94it/s, Loss=0.0293708, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:11<07:26, 10.94it/s, Loss=0.0312949, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:28, 10.88it/s, Loss=0.0312949, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:12<07:28, 10.88it/s, Loss=0.0264492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:23, 10.98it/s, Loss=0.0264492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:23, 10.98it/s, Loss=0.0307074, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<07:23, 10.96it/s, Loss=0.0307074, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:13<07:23, 10.96it/s, Loss=0.0342349, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<07:25, 10.88it/s, Loss=0.0342349, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:14<07:25, 10.88it/s, Loss=0.0264763, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<07:22, 10.94it/s, Loss=0.0264763, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:15<07:22, 10.94it/s, Loss=0.0393195, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<07:27, 10.79it/s, Loss=0.0393195, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:16<07:27, 10.79it/s, Loss=0.0285648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<07:29, 10.72it/s, Loss=0.0285648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:17<07:29, 10.72it/s, Loss=0.0319152, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:17<07:28, 10.73it/s, Loss=0.0319152, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:18<07:28, 10.73it/s, Loss=0.0250246, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:18<07:24, 10.81it/s, Loss=0.0250246, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:19<07:24, 10.81it/s, Loss=0.0277207, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:43, 11.87it/s, Loss=0.0277207, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:43, 11.87it/s, Loss=0.0395030, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:19<06:17, 12.67it/s, Loss=0.0395030, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:20<06:17, 12.67it/s, Loss=0.0347734, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:56, 13.38it/s, Loss=0.0347734, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:21<05:56, 13.38it/s, Loss=0.0317816, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:21<05:38, 14.04it/s, Loss=0.0317816, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:21<05:38, 14.04it/s, Loss=0.0335448, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:21<05:29, 14.43it/s, Loss=0.0335448, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:22<05:29, 14.43it/s, Loss=0.0268890, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:22<05:20, 14.81it/s, Loss=0.0268890, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:23<05:20, 14.81it/s, Loss=0.0326837, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:14, 15.05it/s, Loss=0.0326837, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:14, 15.05it/s, Loss=0.0373581, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:23<05:13, 15.08it/s, Loss=0.0373581, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:24<05:13, 15.08it/s, Loss=0.0314759, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:11, 15.13it/s, Loss=0.0314759, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:11, 15.13it/s, Loss=0.0297795, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:24<05:05, 15.37it/s, Loss=0.0297795, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [420,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:25<06:32, 11.98it/s, Loss=0.0297795, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Missing colmap data: 431_60829_118045\n",
      "Generating GS for 429_60373_116969\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60373_116969\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0380366, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:59, 10.41it/s, Loss=0.0380366, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:59, 10.41it/s, Loss=0.0349144, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:45, 10.69it/s, Loss=0.0349144, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:45, 10.69it/s, Loss=0.0321718, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:35, 10.90it/s, Loss=0.0321718, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:35, 10.90it/s, Loss=0.0255812, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:32, 10.97it/s, Loss=0.0255812, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:32, 10.97it/s, Loss=0.0274894, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<07:32, 10.93it/s, Loss=0.0274894, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<07:32, 10.93it/s, Loss=0.0237680, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<07:33, 10.89it/s, Loss=0.0237680, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:06<07:33, 10.89it/s, Loss=0.0229043, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<07:34, 10.86it/s, Loss=0.0229043, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:07<07:34, 10.86it/s, Loss=0.0252041, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<07:32, 10.86it/s, Loss=0.0252041, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:08<07:32, 10.86it/s, Loss=0.0241031, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<07:28, 10.95it/s, Loss=0.0241031, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:09<07:28, 10.95it/s, Loss=0.0259157, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<07:27, 10.96it/s, Loss=0.0259157, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:10<07:27, 10.96it/s, Loss=0.0216023, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<07:27, 10.93it/s, Loss=0.0216023, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:11<07:27, 10.93it/s, Loss=0.0238650, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:27, 10.90it/s, Loss=0.0238650, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:11<07:27, 10.90it/s, Loss=0.0238915, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<07:27, 10.88it/s, Loss=0.0238915, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:12<07:27, 10.88it/s, Loss=0.0223446, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<07:25, 10.92it/s, Loss=0.0223446, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:13<07:25, 10.92it/s, Loss=0.0203631, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<07:23, 10.94it/s, Loss=0.0203631, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:14<07:23, 10.94it/s, Loss=0.0206492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<07:22, 10.93it/s, Loss=0.0206492, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:15<07:22, 10.93it/s, Loss=0.0231016, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<07:23, 10.89it/s, Loss=0.0231016, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:16<07:23, 10.89it/s, Loss=0.0237066, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<07:24, 10.85it/s, Loss=0.0237066, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:17<07:24, 10.85it/s, Loss=0.0237256, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:17<07:22, 10.87it/s, Loss=0.0237256, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:18<07:22, 10.87it/s, Loss=0.0202766, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:18<07:18, 10.94it/s, Loss=0.0202766, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:19<07:18, 10.94it/s, Loss=0.0223898, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:44, 11.83it/s, Loss=0.0223898, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:19<06:44, 11.83it/s, Loss=0.0234896, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:19<06:12, 12.83it/s, Loss=0.0234896, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:20<06:12, 12.83it/s, Loss=0.0204798, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:49, 13.64it/s, Loss=0.0204798, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:20<05:49, 13.64it/s, Loss=0.0209630, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:20<05:34, 14.23it/s, Loss=0.0209630, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:21<05:34, 14.23it/s, Loss=0.0219442, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:21<05:26, 14.56it/s, Loss=0.0219442, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:22<05:26, 14.56it/s, Loss=0.0206788, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:22<05:19, 14.85it/s, Loss=0.0206788, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:22<05:19, 14.85it/s, Loss=0.0227807, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:22<05:13, 15.08it/s, Loss=0.0227807, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:23<05:13, 15.08it/s, Loss=0.0192978, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:23<05:08, 15.31it/s, Loss=0.0192978, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:24<05:08, 15.31it/s, Loss=0.0189716, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:04, 15.49it/s, Loss=0.0189716, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:24<05:04, 15.49it/s, Loss=0.0216835, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:24<05:00, 15.63it/s, Loss=0.0216835, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:25<05:00, 15.63it/s, Loss=0.0230661, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:25<04:41, 16.67it/s, Loss=0.0230661, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:25<04:41, 16.67it/s, Loss=0.0248319, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:25<04:27, 17.53it/s, Loss=0.0248319, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:26<04:27, 17.53it/s, Loss=0.0193459, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:26<04:15, 18.27it/s, Loss=0.0193459, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:26<04:15, 18.27it/s, Loss=0.0214232, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:26<04:08, 18.78it/s, Loss=0.0214232, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:27<04:08, 18.78it/s, Loss=0.0184847, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:27<04:01, 19.28it/s, Loss=0.0184847, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:27<04:01, 19.28it/s, Loss=0.0208676, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:27<03:57, 19.57it/s, Loss=0.0208676, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:28<03:57, 19.57it/s, Loss=0.0203174, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:28<03:53, 19.82it/s, Loss=0.0203174, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:28<03:53, 19.82it/s, Loss=0.0205082, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:28<03:50, 20.01it/s, Loss=0.0205082, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:29<03:50, 20.01it/s, Loss=0.0158296, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:29<03:47, 20.30it/s, Loss=0.0158296, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:29<03:47, 20.30it/s, Loss=0.0172050, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:29<03:45, 20.40it/s, Loss=0.0172050, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:30<03:45, 20.40it/s, Loss=0.0200999, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:30<03:36, 21.20it/s, Loss=0.0200999, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:30<03:36, 21.20it/s, Loss=0.0232270, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:30<03:27, 22.03it/s, Loss=0.0232270, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:30<03:27, 22.03it/s, Loss=0.0194341, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:30<03:20, 22.78it/s, Loss=0.0194341, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:31<03:20, 22.78it/s, Loss=0.0198043, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:31<03:16, 23.17it/s, Loss=0.0198043, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:31<03:16, 23.17it/s, Loss=0.0186418, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:31<03:12, 23.61it/s, Loss=0.0186418, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:32<03:12, 23.61it/s, Loss=0.0205837, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:32<03:09, 23.99it/s, Loss=0.0205837, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:32<03:09, 23.99it/s, Loss=0.0194589, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:32<03:07, 24.12it/s, Loss=0.0194589, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:32<03:07, 24.12it/s, Loss=0.0215468, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:32<03:05, 24.31it/s, Loss=0.0215468, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:33<03:05, 24.31it/s, Loss=0.0170101, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:33<03:03, 24.59it/s, Loss=0.0170101, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:33<03:03, 24.59it/s, Loss=0.0181618, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|█         | 500/5000 [00:33<03:02, 24.63it/s, Loss=0.0181618, Depth Loss=0.0000000, Number Gaussians=124293]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [24,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [14,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [55,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [26,0,0], thread: [43,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [97,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [7,0,0], thread: [35,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [7,0,0], thread: [58,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [7,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [90,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:  10%|█         | 500/5000 [00:33<05:04, 14.79it/s, Loss=0.0181618, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "\n",
      "Generating GS for 431_60877_118374\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60877_118374\n",
      "Generating GS for 433_61489_120178\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/433_61489_120178\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0175780, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<06:43, 12.37it/s, Loss=0.0175780, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<06:43, 12.37it/s, Loss=0.0153242, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:24, 12.94it/s, Loss=0.0153242, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:24, 12.94it/s, Loss=0.0169400, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:15, 13.23it/s, Loss=0.0169400, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:15, 13.23it/s, Loss=0.0132728, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:09, 13.42it/s, Loss=0.0132728, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:09, 13.42it/s, Loss=0.0162151, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:03<06:11, 13.33it/s, Loss=0.0162151, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:11, 13.33it/s, Loss=0.0129575, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:08, 13.39it/s, Loss=0.0129575, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:08, 13.39it/s, Loss=0.0121657, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:05, 13.48it/s, Loss=0.0121657, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:05, 13.48it/s, Loss=0.0178009, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:07, 13.38it/s, Loss=0.0178009, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:07, 13.38it/s, Loss=0.0144884, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:06<06:07, 13.37it/s, Loss=0.0144884, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:07, 13.37it/s, Loss=0.0142938, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:07<06:08, 13.29it/s, Loss=0.0142938, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:08, 13.29it/s, Loss=0.0141291, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:08, 13.26it/s, Loss=0.0141291, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:08, 13.26it/s, Loss=0.0146097, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:07, 13.28it/s, Loss=0.0146097, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:07, 13.28it/s, Loss=0.0140019, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:09<06:08, 13.22it/s, Loss=0.0140019, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:08, 13.22it/s, Loss=0.0115951, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:10<06:07, 13.21it/s, Loss=0.0115951, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:07, 13.21it/s, Loss=0.0137311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:11<06:06, 13.25it/s, Loss=0.0137311, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:06, 13.25it/s, Loss=0.0121667, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:03, 13.32it/s, Loss=0.0121667, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:03, 13.32it/s, Loss=0.0112240, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:12<06:02, 13.33it/s, Loss=0.0112240, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:02, 13.33it/s, Loss=0.0131203, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:13<06:00, 13.38it/s, Loss=0.0131203, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<06:00, 13.38it/s, Loss=0.0150140, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:14<06:01, 13.29it/s, Loss=0.0150140, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:01, 13.29it/s, Loss=0.0127098, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:59, 13.36it/s, Loss=0.0127098, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:15<05:59, 13.36it/s, Loss=0.0139831, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:15<05:27, 14.65it/s, Loss=0.0139831, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:16<05:27, 14.65it/s, Loss=0.0151204, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<05:01, 15.86it/s, Loss=0.0151204, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:16<05:01, 15.86it/s, Loss=0.0132646, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:16<04:41, 16.93it/s, Loss=0.0132646, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:17<04:41, 16.93it/s, Loss=0.0114151, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:28, 17.71it/s, Loss=0.0114151, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:17<04:28, 17.71it/s, Loss=0.0144199, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:17<04:20, 18.24it/s, Loss=0.0144199, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:20, 18.24it/s, Loss=0.0143766, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:15, 18.58it/s, Loss=0.0143766, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:18<04:15, 18.58it/s, Loss=0.0154330, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:18<04:10, 18.87it/s, Loss=0.0154330, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:10, 18.87it/s, Loss=0.0135201, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:07, 19.09it/s, Loss=0.0135201, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:19<04:07, 19.09it/s, Loss=0.0125710, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:19<04:05, 19.20it/s, Loss=0.0125710, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:05, 19.20it/s, Loss=0.0161785, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<04:04, 19.26it/s, Loss=0.0161785, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:20<04:04, 19.26it/s, Loss=0.0132973, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:20<03:46, 20.69it/s, Loss=0.0132973, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▌         | 310/5000 [00:20<03:46, 20.69it/s, Loss=0.0133264, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:20<03:32, 22.00it/s, Loss=0.0133264, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   6%|▋         | 320/5000 [00:21<03:32, 22.00it/s, Loss=0.0119553, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:21<03:23, 22.98it/s, Loss=0.0119553, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 330/5000 [00:21<03:23, 22.98it/s, Loss=0.0118216, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:21<03:15, 23.82it/s, Loss=0.0118216, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 340/5000 [00:22<03:15, 23.82it/s, Loss=0.0118768, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:22<03:12, 24.20it/s, Loss=0.0118768, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 350/5000 [00:22<03:12, 24.20it/s, Loss=0.0127760, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:22<03:09, 24.55it/s, Loss=0.0127760, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 360/5000 [00:22<03:09, 24.55it/s, Loss=0.0149205, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:22<03:07, 24.64it/s, Loss=0.0149205, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   7%|▋         | 370/5000 [00:23<03:07, 24.64it/s, Loss=0.0109705, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:23<03:05, 24.92it/s, Loss=0.0109705, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 380/5000 [00:23<03:05, 24.92it/s, Loss=0.0115466, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:23<03:03, 25.13it/s, Loss=0.0115466, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 390/5000 [00:24<03:03, 25.13it/s, Loss=0.0114460, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:24<03:01, 25.30it/s, Loss=0.0114460, Depth Loss=0.0000000, Number Gaussians=246537]\n",
      "Training progress:   8%|▊         | 400/5000 [00:24<03:01, 25.30it/s, Loss=0.0114746, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:24<02:52, 26.55it/s, Loss=0.0114746, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 410/5000 [00:24<02:52, 26.55it/s, Loss=0.0120994, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:24<02:44, 27.81it/s, Loss=0.0120994, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   8%|▊         | 420/5000 [00:25<02:44, 27.81it/s, Loss=0.0129194, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:25<02:38, 28.76it/s, Loss=0.0129194, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▊         | 430/5000 [00:25<02:38, 28.76it/s, Loss=0.0141935, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:25<02:35, 29.38it/s, Loss=0.0141935, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 440/5000 [00:25<02:35, 29.38it/s, Loss=0.0110345, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:25<02:31, 29.94it/s, Loss=0.0110345, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 450/5000 [00:26<02:31, 29.94it/s, Loss=0.0122511, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:26<02:30, 30.17it/s, Loss=0.0122511, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 460/5000 [00:26<02:30, 30.17it/s, Loss=0.0122246, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:26<02:28, 30.54it/s, Loss=0.0122246, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:   9%|▉         | 470/5000 [00:26<02:28, 30.54it/s, Loss=0.0149062, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:26<02:28, 30.36it/s, Loss=0.0149062, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 480/5000 [00:26<02:28, 30.36it/s, Loss=0.0106678, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:26<02:27, 30.58it/s, Loss=0.0106678, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|▉         | 490/5000 [00:27<02:27, 30.58it/s, Loss=0.0126758, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "Training progress:  10%|█         | 500/5000 [00:27<02:27, 30.48it/s, Loss=0.0126758, Depth Loss=0.0000000, Number Gaussians=124293]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [85,0,0], thread: [118,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:  10%|█         | 500/5000 [00:27<04:06, 18.25it/s, Loss=0.0126758, Depth Loss=0.0000000, Number Gaussians=124293]\n",
      "\n",
      "Generating GS for 429_60427_117424\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60427_117424\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0292518, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:08, 11.65it/s, Loss=0.0292518, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:08, 11.65it/s, Loss=0.0267924, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<06:46, 12.25it/s, Loss=0.0267924, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<06:46, 12.25it/s, Loss=0.0500154, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<06:34, 12.59it/s, Loss=0.0500154, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<06:34, 12.59it/s, Loss=0.0531211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<06:40, 12.37it/s, Loss=0.0531211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<06:40, 12.37it/s, Loss=0.0311037, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:40, 12.35it/s, Loss=0.0311037, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:40, 12.35it/s, Loss=0.0353499, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:04<06:39, 12.35it/s, Loss=0.0353499, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:39, 12.35it/s, Loss=0.0190687, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:34, 12.48it/s, Loss=0.0190687, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:34, 12.48it/s, Loss=0.0256539, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:38, 12.35it/s, Loss=0.0256539, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<06:38, 12.35it/s, Loss=0.0314211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:37, 12.37it/s, Loss=0.0314211, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<06:37, 12.37it/s, Loss=0.0210300, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:33, 12.45it/s, Loss=0.0210300, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:33, 12.45it/s, Loss=0.0323947, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:08<06:29, 12.56it/s, Loss=0.0323947, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:29, 12.56it/s, Loss=0.0281778, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:09<06:28, 12.56it/s, Loss=0.0281778, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<06:28, 12.56it/s, Loss=0.0199506, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:28, 12.53it/s, Loss=0.0199506, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<06:28, 12.53it/s, Loss=0.0250700, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:27, 12.53it/s, Loss=0.0250700, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<06:27, 12.53it/s, Loss=0.0276620, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:27, 12.50it/s, Loss=0.0276620, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:27, 12.50it/s, Loss=0.0318535, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:12<06:28, 12.45it/s, Loss=0.0318535, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:28, 12.45it/s, Loss=0.0192943, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:13<06:26, 12.49it/s, Loss=0.0192943, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:14<06:26, 12.49it/s, Loss=0.0205283, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:14<06:22, 12.59it/s, Loss=0.0205283, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:15<06:22, 12.59it/s, Loss=0.0470262, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:15<06:22, 12.58it/s, Loss=0.0470262, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:16<06:22, 12.58it/s, Loss=0.0361635, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:16<06:25, 12.46it/s, Loss=0.0361635, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:16<06:25, 12.46it/s, Loss=0.0252670, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:16<05:49, 13.69it/s, Loss=0.0252670, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:17<05:49, 13.69it/s, Loss=0.0300204, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:17<05:19, 14.95it/s, Loss=0.0300204, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:17<05:19, 14.95it/s, Loss=0.0226912, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:17<04:58, 15.97it/s, Loss=0.0226912, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:18<04:58, 15.97it/s, Loss=0.0350501, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:18<04:45, 16.66it/s, Loss=0.0350501, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:18<04:45, 16.66it/s, Loss=0.0204621, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:18<04:35, 17.27it/s, Loss=0.0204621, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:19<04:35, 17.27it/s, Loss=0.0262214, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:19<04:30, 17.53it/s, Loss=0.0262214, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:19<04:30, 17.53it/s, Loss=0.0212206, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:19<04:26, 17.76it/s, Loss=0.0212206, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:20<04:26, 17.76it/s, Loss=0.0607689, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:20<04:24, 17.87it/s, Loss=0.0607689, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:20<04:24, 17.87it/s, Loss=0.0220718, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:20<04:19, 18.15it/s, Loss=0.0220718, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:21<04:19, 18.15it/s, Loss=0.0220235, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:21<04:16, 18.29it/s, Loss=0.0220235, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [218,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:21<05:37, 13.93it/s, Loss=0.0220235, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 429_60368_116964\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/429_60368_116964\n",
      "Generating GS for 431_60951_118764\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/431_60951_118764\n",
      "Error running script. Return code: 1\n",
      "Error output:\n",
      "\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "Training progress:   0%|          | 0/5000 [00:00<?, ?it/s, Loss=0.0345315, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:00<07:28, 11.12it/s, Loss=0.0345315, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 10/5000 [00:01<07:28, 11.12it/s, Loss=0.0306950, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:01<07:11, 11.54it/s, Loss=0.0306950, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   0%|          | 20/5000 [00:02<07:11, 11.54it/s, Loss=0.0340239, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:02<07:00, 11.82it/s, Loss=0.0340239, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 30/5000 [00:03<07:00, 11.82it/s, Loss=0.0353648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:03<07:01, 11.76it/s, Loss=0.0353648, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 40/5000 [00:04<07:01, 11.76it/s, Loss=0.0234665, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:04<06:58, 11.82it/s, Loss=0.0234665, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 50/5000 [00:05<06:58, 11.82it/s, Loss=0.0266224, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:58, 11.79it/s, Loss=0.0266224, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|          | 60/5000 [00:05<06:58, 11.79it/s, Loss=0.0197835, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:05<06:56, 11.83it/s, Loss=0.0197835, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   1%|▏         | 70/5000 [00:06<06:56, 11.83it/s, Loss=0.0212932, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:06<06:54, 11.88it/s, Loss=0.0212932, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 80/5000 [00:07<06:54, 11.88it/s, Loss=0.0255905, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:07<06:52, 11.89it/s, Loss=0.0255905, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 90/5000 [00:08<06:52, 11.89it/s, Loss=0.0235269, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:08<06:52, 11.87it/s, Loss=0.0235269, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 100/5000 [00:09<06:52, 11.87it/s, Loss=0.0219636, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:09<06:51, 11.89it/s, Loss=0.0219636, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 110/5000 [00:10<06:51, 11.89it/s, Loss=0.0192332, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<06:50, 11.87it/s, Loss=0.0192332, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   2%|▏         | 120/5000 [00:10<06:50, 11.87it/s, Loss=0.0188897, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:10<06:50, 11.88it/s, Loss=0.0188897, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 130/5000 [00:11<06:50, 11.88it/s, Loss=0.0187533, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:11<06:48, 11.91it/s, Loss=0.0187533, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 140/5000 [00:12<06:48, 11.91it/s, Loss=0.0173098, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:12<06:46, 11.93it/s, Loss=0.0173098, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 150/5000 [00:13<06:46, 11.93it/s, Loss=0.0210819, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:13<06:46, 11.91it/s, Loss=0.0210819, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 160/5000 [00:14<06:46, 11.91it/s, Loss=0.0214108, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:14<06:45, 11.90it/s, Loss=0.0214108, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   3%|▎         | 170/5000 [00:15<06:45, 11.90it/s, Loss=0.0201640, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:15<06:46, 11.86it/s, Loss=0.0201640, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▎         | 180/5000 [00:16<06:46, 11.86it/s, Loss=0.0183206, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:16<06:44, 11.89it/s, Loss=0.0183206, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 190/5000 [00:16<06:44, 11.89it/s, Loss=0.0177303, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:16<06:42, 11.92it/s, Loss=0.0177303, Depth Loss=0.0000000, Number Gaussians=980001]\n",
      "Training progress:   4%|▍         | 200/5000 [00:17<06:42, 11.92it/s, Loss=0.0193270, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:17<06:08, 13.01it/s, Loss=0.0193270, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 210/5000 [00:18<06:08, 13.01it/s, Loss=0.0203942, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:18<05:40, 14.06it/s, Loss=0.0203942, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   4%|▍         | 220/5000 [00:18<05:40, 14.06it/s, Loss=0.0183323, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:18<05:18, 14.99it/s, Loss=0.0183323, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 230/5000 [00:19<05:18, 14.99it/s, Loss=0.0181011, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:19<05:04, 15.65it/s, Loss=0.0181011, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▍         | 240/5000 [00:19<05:04, 15.65it/s, Loss=0.0188024, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:19<04:55, 16.07it/s, Loss=0.0188024, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 250/5000 [00:20<04:55, 16.07it/s, Loss=0.0172585, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:20<04:49, 16.39it/s, Loss=0.0172585, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 260/5000 [00:20<04:49, 16.39it/s, Loss=0.0167838, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:20<04:42, 16.76it/s, Loss=0.0167838, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   5%|▌         | 270/5000 [00:21<04:42, 16.76it/s, Loss=0.0172466, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:21<04:39, 16.92it/s, Loss=0.0172466, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 280/5000 [00:22<04:39, 16.92it/s, Loss=0.0154035, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:22<04:35, 17.07it/s, Loss=0.0154035, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 290/5000 [00:22<04:35, 17.07it/s, Loss=0.0163914, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "Training progress:   6%|▌         | 300/5000 [00:22<04:33, 17.20it/s, Loss=0.0163914, Depth Loss=0.0000000, Number Gaussians=491025]../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [122,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [205,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [257,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [193,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [85,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 265, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\", line 150, in training\n",
      "    gaussians.densify_and_prune(\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 510, in densify_and_prune\n",
      "    self.prune_points(~keep_mask)            \n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 342, in prune_points\n",
      "    optimizable_tensors = self._prune_optimizer(valid_points_mask)\n",
      "  File \"/workspace/GSDiffusionModel/submodules/gaussian-splatting/scene/gaussian_model.py\", line 327, in _prune_optimizer\n",
      "    stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][mask]\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Training progress:   6%|▌         | 300/5000 [00:22<05:55, 13.21it/s, Loss=0.0163914, Depth Loss=0.0000000, Number Gaussians=491025]\n",
      "\n",
      "Generating GS for 427_60021_116224\n",
      "/workspace/GSDiffusionModel/submodules/gaussian-splatting/train.py\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/427_60021_116224\n"
     ]
    }
   ],
   "source": [
    "# Convert dataset to GS\n",
    "\n",
    "!cd .. && python -m scripts.dataset.labeled.create_gs_dataset --category hydrant --network_gui False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for config file in /workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/134_15449_31106/cfg_args\n",
      "Config file found: /workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/134_15449_31106/cfg_args\n",
      "Rendering /workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/134_15449_31106\n",
      "/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/134_15449_31106/point_cloud [01/09 16:24:53]\n",
      "['iteration_5000'] [01/09 16:24:53]\n",
      "Loading trained model at iteration 5000 [01/09 16:24:53]\n",
      "Reading camera 202/202 [01/09 16:24:53]\n",
      "Loading Training Cameras [01/09 16:24:54]\n",
      "Loading Test Cameras [01/09 16:25:09]\n",
      "Rendering progress: 100%|█████████████████████| 202/202 [01:15<00:00,  2.66it/s]\n",
      "Rendering progress: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python submodules/gaussian-splatting/render.py -m /workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/134_15449_31106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = \"/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant\"\n",
    "subdirs = [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]\n",
    "\n",
    "good_models = 0\n",
    "for subdir in subdirs:\n",
    "    if os.path.isdir(os.path.join(directory, subdir, \"point_cloud\", \"iteration_5000\")):\n",
    "        good_models += 1\n",
    "\n",
    "print(good_models)\n",
    "print(len(subdirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.25789368, 3.219174, 0.526191, 0., 0., 0., 0.77778184, -0.1289579, -0.1867556, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.21480489, -3.6580927, -4.673573, -7.02538, 0.9107714, -0.07742789, -0.13270347, 0.04195821)\n",
      "(1.1682923, 1.7936636, 0.52316767, 0., 0., 0., 1.449135, 1.6223454, 1.2391286, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.1313254, -3.9600298, -4.64228, -8.332485, 0.6842121, -0.15861389, -0.3410596, 0.1403791)\n",
      "(0.72004765, -0.69008785, -1.1577082, 0., 0., 0., 1.5197033, 1.5593966, 1.5181926, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.0621912, -5.4464774, -3.740391, -3.350712, 0.53566664, -0.02271316, 0.3098637, -0.39094448)\n",
      "(-0.12196986, 1.7991607, 0.1462651, 0., 0., 0., 1.023084, -0.068035, -0.07166755, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.20178762, -3.3067787, -4.889029, -5.203135, 0.8962426, 0.079577, -0.06049912, 0.12797777)\n",
      "(-1.2492461, 0.81883234, 0.72980016, 0., 0., 0., 1.2385488, 1.5446198, 1.3642988, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.1091067, -7.0083904, -4.613538, -3.9308805, 0.7260986, -0.3182556, -0.17939654, 0.15584661)\n",
      "Modified PLY file saved: /workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12677_24990/point_cloud/iteration_5000/point_cloud.ply\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Image list with two lines of data per image:\n",
      "#   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
      "#   POINTS2D[] as (X, Y, POINT3D_ID)\n",
      "# Number of images: 202, mean observations per image: 2500\n",
      "1 0.43923069735190345 -0.5312714836975936 -0.012955058327317137 -0.7243336051690912 -0.010589353740215302 2.3088395595550537 9.083442687988281 1 frame000001.jpg\n",
      "48 0.06198152213049953 -0.05356958804565001 0.010805305963446976 0.9965800697957199 0.38255879282951355 0.7826452851295471 7.525020122528076 48 frame000048.jpg\n"
     ]
    }
   ],
   "source": [
    "with open(\"/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/sparse/0/images.txt\", \"r\") as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    print('\\n'.join(lines[0:5]))\n",
    "    print(lines[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Camera list with one line of data per camera:\n",
      "#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[6]\n",
      "# Number of cameras: 202\n",
      "1 PINHOLE 719 1646 247.01188123953466 565.4819979419667 359 823\n",
      "2 PINHOLE 719 1646 246.9641622844523 565.3727553827656 359 823\n",
      "48 PINHOLE 719 1646 244.61185364354063 559.9876371311098 359 823\n"
     ]
    }
   ],
   "source": [
    "with open(\"/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/sparse/0/cameras.txt\", \"r\") as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    print('\\n'.join(lines[0:5]))\n",
    "    print(lines[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# 3D point list with one line of data per point:', '#   POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)', '# Number of points: 980001, mean track length: 0.0', '1 -0.4043790102005005 -1.2760553359985352 -0.4534003734588623 156 161 161 0.0', '2 0.3273124694824219 -0.9985339641571045 0.8547940254211426 220 220 230 0.0']\n",
      "X Range: [-1.280186414718628, 1.9200682640075684]\n",
      "Y Range: [-1.9406838417053223, 3.504551887512207]\n",
      "Z Range: [-1.3880338668823242, 3.6833600997924805]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/sparse/0/points3D.txt\", \"r\") as f:\n",
    "    lines = f.read().splitlines()  # Use splitlines to handle newlines correctly\n",
    "    print(lines[:5])\n",
    "\n",
    "    x_range = [float('inf'), float('-inf')]\n",
    "    y_range = [float('inf'), float('-inf')]\n",
    "    z_range = [float('inf'), float('-inf')]\n",
    "\n",
    "    for line in lines[3:]:\n",
    "        if line.strip():  # Skip empty lines\n",
    "            segs = line.split(' ')\n",
    "\n",
    "            # Convert string values to floats\n",
    "            x = float(segs[1])\n",
    "            y = float(segs[2])\n",
    "            z = float(segs[3])\n",
    "\n",
    "            # Update x_range\n",
    "            if x < x_range[0]:\n",
    "                x_range[0] = x\n",
    "            if x > x_range[1]:\n",
    "                x_range[1] = x\n",
    "\n",
    "            # Update y_range\n",
    "            if y < y_range[0]:\n",
    "                y_range[0] = y\n",
    "            if y > y_range[1]:\n",
    "                y_range[1] = y\n",
    "\n",
    "            # Update z_range\n",
    "            if z < z_range[0]:\n",
    "                z_range[0] = z\n",
    "            if z > z_range[1]:\n",
    "                z_range[1] = z\n",
    "\n",
    "    print(\"X Range:\", x_range)\n",
    "    print(\"Y Range:\", y_range)\n",
    "    print(\"Z Range:\", z_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Image list with two lines of data per image:', '#   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME', '#   POINTS2D[] as (X, Y, POINT3D_ID)', '# Number of images: 202, mean observations per image: 2500', '1 0.7243336051690914 0.012955058327316998 -0.531271483697594 -0.43923069735190345 -0.010589353740215302 2.3088395595550537 9.083442687988281 1 frame000001.jpg']\n",
      "X Range: [-1.2386572360992432, 0.781455934047699]\n",
      "Y Range: [-0.30876585841178894, 2.3088395595550537]\n",
      "Z Range: [6.0859150886535645, 9.089887619018555]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/sparse/0/images.txt\", \"r\") as f:\n",
    "    lines = f.read().splitlines()  # Use splitlines to handle newlines correctly\n",
    "    print(lines[:5])\n",
    "\n",
    "    x_range = [float('inf'), float('-inf')]\n",
    "    y_range = [float('inf'), float('-inf')]\n",
    "    z_range = [float('inf'), float('-inf')]\n",
    "\n",
    "    for line in lines[4:]:\n",
    "        if line.strip():  # Skip empty lines\n",
    "            segs = line.split(' ')\n",
    "\n",
    "            # Convert string values to floats\n",
    "            x = float(segs[5])\n",
    "            y = float(segs[6])\n",
    "            z = float(segs[7])\n",
    "\n",
    "            # Update x_range\n",
    "            if x < x_range[0]:\n",
    "                x_range[0] = x\n",
    "            if x > x_range[1]:\n",
    "                x_range[1] = x\n",
    "\n",
    "            # Update y_range\n",
    "            if y < y_range[0]:\n",
    "                y_range[0] = y\n",
    "            if y > y_range[1]:\n",
    "                y_range[1] = y\n",
    "\n",
    "            # Update z_range\n",
    "            if z < z_range[0]:\n",
    "                z_range[0] = z\n",
    "            if z > z_range[1]:\n",
    "                z_range[1] = z\n",
    "\n",
    "    print(\"X Range:\", x_range)\n",
    "    print(\"Y Range:\", y_range)\n",
    "    print(\"Z Range:\", z_range)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CO3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.00000383603373\n",
      "161.0000028179381\n",
      "161.0000028179381\n"
     ]
    }
   ],
   "source": [
    "def SH2RGB(sh):\n",
    "    return sh * 0.28209479177387814 + 0.5\n",
    "\n",
    "print(SH2RGB(0.39619562)*255) \n",
    "print(SH2RGB(0.4657036)* 255) \n",
    "print(SH2RGB(0.4657036)* 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.404379, -1.2760553, -0.45340037, 0., 0., 0., 0.39619562, 0.4657036, 0.4657036, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -2.1972246, -5.257743, -5.257743, -5.257743, 1., 0., 0., 0.)\n",
      "(0.32731247, -0.99853396, 0.854794, 0., 0., 0., 1.2858979, 1.2858979, 1.4249139, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -2.1972246, -5.399721, -5.399721, -5.399721, 1., 0., 0., 0.)\n",
      "(0.49003685, -0.7794697, -0.8508241, 0., 0., 0., 1.2997994, 1.2580947, 1.2580947, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -2.1972246, -4.3777213, -4.3777213, -4.3777213, 1., 0., 0., 0.)\n",
      "(-0.60084534, 1.0265565, 0.28574705, 0., 0., 0., -0.8549482, -0.78544027, -0.91055477, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -2.1972246, -4.638318, -4.638318, -4.638318, 1., 0., 0., 0.)\n",
      "(-0.00624979, -0.960207, -1.0422194, 0., 0., 0., 0.7854404, 0.81324357, 0.81324357, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -2.1972246, -4.588223, -4.588223, -4.588223, 1., 0., 0., 0.)\n",
      "ply\n",
      "format binary_little_endian 1.0\n",
      "element vertex 980001\n",
      "property float x\n",
      "property float y\n",
      "property float z\n",
      "property float nx\n",
      "property float ny\n",
      "property float nz\n",
      "property float f_dc_0\n",
      "property float f_dc_1\n",
      "property float f_dc_2\n",
      "property float f_rest_0\n",
      "property float f_rest_1\n",
      "property float f_rest_2\n",
      "property float f_rest_3\n",
      "property float f_rest_4\n",
      "property float f_rest_5\n",
      "property float f_rest_6\n",
      "property float f_rest_7\n",
      "property float f_rest_8\n",
      "property float f_rest_9\n",
      "property float f_rest_10\n",
      "property float f_rest_11\n",
      "property float f_rest_12\n",
      "property float f_rest_13\n",
      "property float f_rest_14\n",
      "property float f_rest_15\n",
      "property float f_rest_16\n",
      "property float f_rest_17\n",
      "property float f_rest_18\n",
      "property float f_rest_19\n",
      "property float f_rest_20\n",
      "property float f_rest_21\n",
      "property float f_rest_22\n",
      "property float f_rest_23\n",
      "property float f_rest_24\n",
      "property float f_rest_25\n",
      "property float f_rest_26\n",
      "property float f_rest_27\n",
      "property float f_rest_28\n",
      "property float f_rest_29\n",
      "property float f_rest_30\n",
      "property float f_rest_31\n",
      "property float f_rest_32\n",
      "property float f_rest_33\n",
      "property float f_rest_34\n",
      "property float f_rest_35\n",
      "property float f_rest_36\n",
      "property float f_rest_37\n",
      "property float f_rest_38\n",
      "property float f_rest_39\n",
      "property float f_rest_40\n",
      "property float f_rest_41\n",
      "property float f_rest_42\n",
      "property float f_rest_43\n",
      "property float f_rest_44\n",
      "property float opacity\n",
      "property float scale_0\n",
      "property float scale_1\n",
      "property float scale_2\n",
      "property float rot_0\n",
      "property float rot_1\n",
      "property float rot_2\n",
      "property float rot_3\n",
      "end_header\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData\n",
    "\n",
    "# Load the PLY file\n",
    "ply_data = PlyData.read('/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/point_cloud/iteration_10/point_cloud.ply')  # Replace with your PLY file path\n",
    "\n",
    "# Access the vertex data (assuming the file contains vertices)\n",
    "vertex_data = ply_data['vertex']\n",
    "\n",
    "# Print a few lines of the vertex data\n",
    "for i in range(5):  # Adjust the range to view more or fewer lines\n",
    "    print(vertex_data[i])\n",
    "print(ply_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "new_data = np.array(\n",
    "    [(vertex[0], vertex[1], vertex[2], SH2RGB(vertex[6])*255, SH2RGB(vertex[7])*255, SH2RGB(vertex[8])*255) for vertex in vertex_data],\n",
    "    dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]\n",
    ")\n",
    "\n",
    "# Create the PLY element\n",
    "vertex_element = PlyElement.describe(new_data, 'vertex')\n",
    "\n",
    "# Write to PLY file\n",
    "PlyData([vertex_element]).write('/workspace/GSDiffusionModel/data/labeled_gs/raw/hydrant/hydrant/106_12653_23216/point_cloud/iteration_10/output.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PlyHeaderParseError",
     "evalue": "line 1: expected 'ply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPlyHeaderParseError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplyfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PlyData\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the PLY file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ply_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlyData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/south-building/sparse/0/points3D.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your PLY file path\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Access the vertex data (assuming the file contains vertices)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vertex_data \u001b[38;5;241m=\u001b[39m ply_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertex\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/plyfile.py:159\u001b[0m, in \u001b[0;36mPlyData.read\u001b[0;34m(stream, mmap, known_list_len)\u001b[0m\n\u001b[1;32m    157\u001b[0m (must_close, stream) \u001b[38;5;241m=\u001b[39m _open_stream(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mPlyData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mtext:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/plyfile.py:121\u001b[0m, in \u001b[0;36mPlyData._parse_header\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_header\u001b[39m(stream):\n\u001b[0;32m--> 121\u001b[0m     parser \u001b[38;5;241m=\u001b[39m _PlyHeaderParser(\u001b[43m_PlyHeaderLines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PlyData(\n\u001b[1;32m    123\u001b[0m         [PlyElement(\u001b[38;5;241m*\u001b[39me) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39melements],\n\u001b[1;32m    124\u001b[0m         parser\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m         parser\u001b[38;5;241m.\u001b[39mobj_info\n\u001b[1;32m    128\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/plyfile.py:1272\u001b[0m, in \u001b[0;36m_PlyHeaderLines.__init__\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mply\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PlyHeaderParseError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mply\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mPlyHeaderParseError\u001b[0m: line 1: expected 'ply'"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData\n",
    "\n",
    "# Load the PLY file\n",
    "ply_data = PlyData.read('/workspace/south-building/point_cloud/iteration_10/point_cloud.ply')  # Replace with your PLY file path\n",
    "\n",
    "# Access the vertex data (assuming the file contains vertices)\n",
    "vertex_data = ply_data['vertex']\n",
    "\n",
    "# Print a few lines of the vertex data\n",
    "for i in range(5):  # Adjust the range to view more or fewer lines\n",
    "    print(vertex_data[i])\n",
    "print(ply_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from co3d.dataset.data_types import (\n",
    "    load_dataclass_jgzip, FrameAnnotation, SequenceAnnotation\n",
    ")\n",
    "\n",
    "category_frame_annotations = load_dataclass_jgzip(\n",
    "    f\"../data/labeled_gs/raw/hydrant/hydrant/frame_annotations.jgz\", List[FrameAnnotation]\n",
    ")\n",
    "category_sequence_annotations = load_dataclass_jgzip(\n",
    "    f\"../data/labeled_gs/raw/hydrant/hydrant/sequence_annotations.jgz\", List[SequenceAnnotation]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrameAnnotation(sequence_name='605_94563_187702', frame_number=6, frame_timestamp=0.3845771144278607, image=ImageAnnotation(path='hydrant/605_94563_187702/images/frame000006.jpg', size=(1268, 713)), depth=DepthAnnotation(path='hydrant/605_94563_187702/depths/frame000006.jpg.geometric.png', scale_adjustment=1.0, mask_path='hydrant/605_94563_187702/depth_masks/frame000006.png'), mask=MaskAnnotation(path='hydrant/605_94563_187702/masks/frame000006.png', mass=1000000), viewpoint=ViewpointAnnotation(R=((-0.9998694658279419, -0.001025464036501944, -0.016123276203870773), (0.0009754493949003518, -0.999994695186615, 0.003109571523964405), (-0.016126379370689392, 0.003093438223004341, 0.9998651742935181)), T=(-0.06160982325673103, 1.5896116495132446, 14.91888427734375), focal_length=(3.4211699962615967, 3.4211699962615967), principal_point=(0.001402524532750249, -0.001402524532750249), intrinsics_format='ndc_isotropic'), meta={'frame_type': 'test_unseen', 'frame_splits': ['singlesequence_hydrant_test_0_unseen'], 'eval_batch_maps': []})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_frame_annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload labeled dataset to HuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n",
      "134_15449_31106\n",
      "216_22871_50171\n",
      "206_21815_46194\n",
      "216_22839_48459\n",
      "194_20947_44496\n",
      "106_12698_26785\n",
      "206_21819_46352\n",
      "106_12686_26118\n",
      "194_20940_43635\n",
      "106_12669_24034\n",
      "194_20957_44512\n",
      "250_26738_53523\n",
      "194_20891_40947\n",
      "185_19998_39437\n",
      "194_20934_42349\n",
      "194_20956_44543\n",
      "194_20938_42675\n",
      "167_18184_34441\n",
      "194_20882_40735\n",
      "194_20943_43312\n",
      "194_20931_42673\n",
      "216_22856_49632\n",
      "167_18192_34876\n",
      "157_17288_33665\n",
      "216_22862_49638\n",
      "167_18177_33907\n",
      "106_12687_26288\n",
      "194_20902_41099\n",
      "216_22840_48460\n",
      "185_19974_36741\n",
      "134_15450_30933\n",
      "216_22855_49631\n",
      "79_8251_17496\n",
      "206_21817_46200\n",
      "250_26744_53526\n",
      "106_12660_22718\n",
      "134_15456_31334\n",
      "116_13651_28370\n",
      "244_25997_52016\n",
      "116_13648_27584\n",
      "250_26747_53540\n",
      "106_12653_23216\n",
      "134_15451_31119\n",
      "216_22806_47497\n",
      "216_22805_47495\n",
      "185_19984_37720\n",
      "216_22815_47624\n",
      "134_15455_31174\n",
      "194_20925_42241\n",
      "116_13660_28980\n",
      "244_25993_51715\n",
      "235_24639_51669\n",
      "194_20879_39973\n",
      "216_22861_49637\n",
      "216_22859_49635\n",
      "157_17285_33524\n",
      "250_26749_52968\n",
      "194_20876_39736\n",
      "167_18176_34398\n",
      "194_20907_41105\n",
      "194_20888_40801\n",
      "206_21818_45959\n",
      "216_22850_49616\n",
      "185_19977_36602\n",
      "216_22867_49765\n",
      "167_18178_34131\n",
      "235_24641_51707\n",
      "157_17275_32769\n",
      "216_22845_49619\n",
      "194_20906_41104\n",
      "185_19989_38870\n",
      "167_18186_34890\n",
      "147_16374_32167\n",
      "250_26741_53521\n",
      "194_20922_42215\n",
      "157_17287_33549\n",
      "106_12648_23157\n",
      "194_20953_43984\n",
      "216_22818_47639\n",
      "106_12677_24990\n",
      "185_19986_38630\n",
      "185_19994_39389\n",
      "216_22857_49633\n",
      "216_22860_49636\n",
      "194_20893_40953\n",
      "250_26746_53530\n",
      "194_20930_42343\n",
      "185_19990_38942\n",
      "194_20928_42530\n",
      "216_22826_47834\n",
      "194_20878_39742\n",
      "216_22854_49630\n",
      "216_22858_49634\n",
      "216_22866_49900\n",
      "167_18181_34401\n",
      "167_18191_34823\n",
      "206_21797_45640\n",
      "116_13653_28885\n",
      "eval_batches\n",
      "set_lists\n",
      "Uploading to HF...\n",
      "Uploading the dataset shards:   0%|                       | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|█████████| 1/1 [00:00<00:00, 17.48ba/s]\u001b[A\n",
      "Uploading the dataset shards: 100%|███████████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "Uploading the dataset shards:   0%|                       | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|█████████| 1/1 [00:00<00:00, 20.09ba/s]\u001b[A\n",
      "Uploading the dataset shards: 100%|███████████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "README.md: 100%|███████████████████████████████| 422/422 [00:00<00:00, 3.12MB/s]\n",
      "Finished uploading\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m scripts.dataset.labeled.upload_to_hf --category hydrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download labeled dataset from S3 bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11801\n",
      "drwxrwxrwx 7 root root 3003630 Aug 30 22:34 .\n",
      "drwxrwxrwx 4 root root 3003630 Aug 30 21:56 ..\n",
      "drwxrwxrwx 8 root root 1004083 Aug 30 21:55 .git\n",
      "-rw-rw-rw- 1 root root      49 Aug 30 21:55 .gitignore\n",
      "drwxrwxrwx 2 root root       1 Aug 30 22:34 .ipynb_checkpoints\n",
      "-rw-rw-rw- 1 root root    2004 Aug 30 21:55 README.md\n",
      "drwxrwxrwx 3 root root 3003630 Aug 30 21:55 data\n",
      "drwxrwxrwx 3 root root 1062694 Aug 30 22:36 notebooks\n",
      "-rw-rw-rw- 1 root root      13 Aug 30 21:55 requirements.txt\n",
      "drwxrwxrwx 3 root root 1000680 Aug 30 22:19 scripts\n"
     ]
    }
   ],
   "source": [
    "!cd .. && ls -la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
